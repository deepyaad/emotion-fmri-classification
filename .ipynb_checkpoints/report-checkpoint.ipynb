{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43d9c1d4-82a3-4a6e-982c-cd2c719372af",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## **Inside Out ML: Emotion Classification from fMRI Using Parcellation and Projection Techniques**\n",
    "\n",
    "#### **Group 36 on Canvas**\n",
    "\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./cover-img.png\" alt=\"image\" width=\"600\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea1e80c-e319-4b24-9e20-71b561ba0c38",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## **Abstract**\n",
    "\n",
    "This study explores feature extraction techniques for analyzing high-dimensional, non-independently distributed data in multi-class classification tasks using functional magnetic resonance imaging (fMRI).Extending beyond the scope of CS 6140 Machine Learning, this investigation aims to establish a protocol for applying machine learning and deep learning methods to fMRI data by identifying meaningful brain parcels and data projections for emotion classification. Keywords: computer vision, functional magnetic resonance imaging (fMRI), multi-class classification, feature extraction, emotion recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea3e83d-84d0-4008-98c4-7971646d758e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## **Introduction**\n",
    "\n",
    "Recent years, researchers have investigated the ability of deep learning and machine learning models to analyze neuroimages. Before applying a model to a dataset, due to the high-dimensionality and density of neuroimaging data, practitioners often reduce dimensions using brain parcellation masks. These masks average voxel values over specific brain parcels, to focus analysis by regions of interest (ROI), rather than by voxel, which can go up to a 1 billion.\n",
    "\n",
    "Given this development, studies have begun to explore best practices for choosing brain parcellations technique for feature extraction. The inspiration for our investigation came from a study that analyzed a teleological approach [B], recommending brain parcellation based on the aim of the study. To expand upon this work. we investigated coefficients of a traditional machine learning model to identify important embeddings and regions of interest for emotion classification.\n",
    "\n",
    "\n",
    "This paper bridges machine learning methodology with neuroscience application by evaluating how both statistical and domain-specific feature extraction techniques affect multi-class classification of emotional states from fMRI data. Our study results will recomend interdisciplinary researchers specific ROI and embeddings to focus on when studying emotion and mood in neurodegenerative, neurodevelopmental and psychiatric disorders.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febecd94-6885-41e3-8ff0-91db827193bc",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "## **Data**\n",
    "\n",
    "The dataset comprises 270 fMRI scans collected from 30 participants by **Northeastern University’s Affective and Brain Sciences Lab**. Each subject was shown emotionally evocative images designed to elicit anger, fear, or disgust. This was followed by a priming word that was either congruent (same emotion as the image), incongruent (different emotion), or neutral (emotionally neutral).\n",
    "\n",
    "Each subject completed all combinations of emotional state and priming condition (3 emotions × 3 priming types = 9 scans per subject), resulting in 270 scans in total. Each scan is stored as a .nii.gz file and labeled with subject ID, emotion state, and priming condition. The classification targets are emotional state and priming condition, while subject ID—used to model the hierarchical structure—introduces non-independence across samples from the same participant.\n",
    "\n",
    "Due to the dataset’s size, it is stored in a Hugging Face dataset and loaded locally. In the future, this setup will be modified to support streaming, avoiding the need to store all 270 .nii.gz files locally.\n",
    "\n",
    "The input data is 4D, with dimensions 270 × 91 × 109 × 91, resulting in 243 million total values (902,629 per scan). This is too large to feed directly into a classifier. Therefore, dimensionality reduction and brain parcellation techniques will be applied, reducing each scan to approximately 20–23 features for downstream modeling.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./sub_16_anger_neutral.png\" alt=\"image\" width=\"600\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d68f25b0-82a7-4a2f-92ef-46308791266d",
   "metadata": {},
   "source": [
    "## **Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be800138-dce2-4857-b3c5-767f1eebcf8b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### **Data Organization**\n",
    "\n",
    "Here is how the project is structured. Review the `README.md` to understand how to navigate the repo and grade the project deliverables.\n",
    "\n",
    "<pre>\n",
    "<strong>emotion-fmri-classification</strong>: project directory\n",
    "├── <strong>requirements.txt</strong>: libraries and packages to install\n",
    "├── <strong>README.md</strong>: run and navigation instructions (including this tree structure)\n",
    "├── <strong>emotion-fmri-neu</strong>: 270 .nii.gz files of fMRI data\n",
    "├── <strong>workflow.ipynb</strong>: full project pipeline, loading \n",
    "├── <strong>output.ipynb</strong>: outputs all information\n",
    "├── <strong>report.ipynb</strong>: Jupyter Notebook Version of report with comprehensive, complete analysis\n",
    "├── <strong>report.pdf</strong>: IEEE Version of report with abridged analysis  \n",
    "├── <strong>presentation.pdf</strong>: slide deck of project overview and analysis  \n",
    "├── <strong>presentation.mov</strong>: 10 min presentation recording of project \n",
    "├── <strong>data</strong>\n",
    "│   ├── <strong>collinearity</strong>\n",
    "│   ├── <strong>cost_function_logs</strong>\n",
    "│   ├── <strong>dimension_reductions</strong>\n",
    "│   ├── <strong>interpretation</strong>\n",
    "│   ├── <strong>parcellations</strong>\n",
    "│   ├── <strong>bivariate_data</strong>\n",
    "│   ├── <strong>models</strong>\n",
    "│   ├── <strong>log_reg_results</strong>\n",
    "│   │   ├── <strong>classification_reports</strong>\n",
    "│   │   ├── <strong>coefficients</strong>\n",
    "│   │   ├── <strong>errors</strong>\n",
    "│   │   └── <strong>metrics</strong>\n",
    "├── <strong>visualizations</strong>\n",
    "│   ├── <strong>atlas_maps</strong>\n",
    "│   ├── <strong>collinearity</strong>\n",
    "│   ├── <strong>confusion_matrices</strong>\n",
    "│   ├── <strong>cost_functions</strong>\n",
    "│   ├── <strong>heteroscedasticity</strong>\n",
    "│   ├── <strong>bivariate_data</strong>\n",
    "│   │   ├── <strong>emotion</strong>\n",
    "│   │   ├── <strong>subject</strong>\n",
    "│   │   └── <strong>priming</strong>\n",
    "└── <strong>cover-image.png</strong>: image from Pixar Movie Inside Out of characters Anger, Disgust and Fear\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee53c6f-bf84-4452-af79-5ecf451be0da",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### Brain Parcellations\n",
    "\n",
    "Brain parcellation is a popular technique for its spatial interpretability and computational efficiency. The nature of neuroimaging data is not a tabular structure, but rather spatial and temporal dependencies to show where and when brain activity occurs. Each data point represents a specific voxel activation value which for fMRI can go up to 1 million features, per image. Aside from high dimensionality, these raw images often contain noisy signals that are not related to blood oxygen level dependent (BOLD) signals, which reflect brain activity. Brain parcellation uses predetermined masker objects or atlas maps to segment the high-dimensional voxel data into groups that represent specific regions of the brain. These regions of interest (ROI) are non-overlapping, and produce a structured signal (an average activation value for each ROI) that can be used as a feature and minimize noise [Pereira].\n",
    "\n",
    "All atlases were accessed using the `nilearn` library, which provides a standardized interface to several widely-used functional neuroimaging templates. Each `.nii.gz` file was first loaded using **Nibabel**, converted to voxel-level arrays, and transformed into 1D feature vectors using the `NiftiLabelsMasker` class in **Nilearn**. The corresponding atlas maps were retrieved via `nilearn.datasets.fetch_atlas_[ATLAS_NAME]`, and stored in a dictionary along with their labels and metadata for reproducibility and interpretability.\n",
    "\n",
    "The following atlases were used in this study:\n",
    "\n",
    "---\n",
    "\n",
    "#### A. Harvard-Oxford Atlases\n",
    "\n",
    "The Harvard-Oxford atlases are probabilistic anatomical maps created from structural MRI data by the Harvard Center for Morphometric Analysis. They segment both cortical and subcortical regions and are widely used in structural parcellation. The Cortical Atlas (48 ROIs), labeled `harvard_oxford_cort_0_1`, encompasses bilateral cortical structures at a 0% probability threshold with a resolution of 1 mm. The Left Cortical Atlas (96 ROIs), designated as harvard_oxford_cortl_0_1, targets cortical regions in the left hemisphere, providing enhanced spatial detail at the same 1 mm resolution. The Subcortical Atlas (21 ROIs), referred to as harvard_oxford_sub_0_1, includes key subcortical structures such as the thalamus, hippocampus, and amygdala, also at 1 mm resolution.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### B. Talairach Atlases\n",
    "\n",
    "The Talairach atlas provides multiple anatomical segmentations of the brain based on tissue type and macrostructural organization. Several variants were included:\n",
    "\n",
    "- **Brodmann Areas (71 ROIs):**  \n",
    "  `talairach_ba` — Segments the brain into Brodmann areas, commonly used in functional localization.\n",
    "\n",
    "- **Gyrus Level (55 ROIs):**  \n",
    "  `talairach_gyrus` — Provides segmentation at the level of cortical gyri.\n",
    "\n",
    "- **Combined Hemi-Lobe-Tissue (22 ROIs total):**  \n",
    "  Merged feature set combining:\n",
    "  - Hemisphere (`talairach_hemi`, 7 ROIs)  \n",
    "  - Lobe (`talairach_lobe`, 12 ROIs)  \n",
    "  - Tissue type (`talairach_tissue`, 3 ROIs)  \n",
    "  Due to their individually low dimensionality, these three were concatenated into a single feature set.\n",
    "\n",
    "---\n",
    "\n",
    "#### C. Schaefer 2018 Atlas\n",
    "\n",
    "- **Schaefer 100 × 17 × 1 (100 ROIs):**  \n",
    "  `schaefer_100_17_1` — A functional atlas based on resting-state fMRI data, dividing the cortex into 100 regions grouped into 17 large-scale networks, at 1 mm resolution.\n",
    "\n",
    "---\n",
    "\n",
    "#### D. AAL (SPM12) Atlas\n",
    "\n",
    "- **AAL SPM12 (116 ROIs):**  \n",
    "  `aal_spm12` — The Automated Anatomical Labeling atlas for SPM12, derived from the MNI single-subject T1 template. It is commonly used for whole-brain anatomical segmentation.\n",
    "\n",
    "---\n",
    "\n",
    "#### E. Juelich Atlas\n",
    "\n",
    "- **Juelich 0 × 1 (62 ROIs):**  \n",
    "  `juelich_0_1` — A probabilistic cytoarchitectonic atlas derived from postmortem histological data, with a threshold of 0 and 1 mm resolution. Distributed via FSL.\n",
    "\n",
    "---\n",
    "\n",
    "These atlases enable diverse views of brain organization—ranging from structural anatomy to functional networks—facilitating the extraction of meaningful and compact features for downstream classification models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57357dc-c8ea-47af-bdda-554947455f7c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### **Dimension Reduction**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### **Sammon Mapping**\n",
    "\n",
    "from open source contirbutor: https://pypi.org/project/sammon-mapping\n",
    "\n",
    "incldued warning about convergence and did not converge\n",
    "\n",
    "attempted to customize from scratch implementation but did converge in time so decided to remove it from analysis\n",
    "\n",
    "output, E = sammon_mapping(input_data, d)\n",
    "                    errors[d] = E\n",
    "\n",
    "\n",
    "#### **Autoencoder**\n",
    "\n",
    "coded from scratch but took too long to compute. didn't include sci-kit learn equivalient\n",
    "\n",
    "#### **Principal Component Analysis**\n",
    "\n",
    "Best practice for PCA is that the number of components is reduced to the minimum number necessary to explain 99% of variance.\n",
    "\n",
    "Which in this case is **226 components**. Below you can see where the curve meets the horizontal line at the 0.99 threshold.\n",
    "\n",
    "fit PCA model\n",
    "pca = PCA()\n",
    "X_test_pca = pca.fit_transform(X)\n",
    "\n",
    "get cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "find the number of components that reach 99% variance\n",
    "n_components_99 = np.argmax(cumulative_variance >= 0.99) + 1\n",
    "\n",
    "didn't include from scratch implementation because of explained variance (if had time would've implemented)\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/cost_functions/PCA.png\" alt=\"image\" width=\"600\" />\n",
    "</div>\n",
    "\n",
    "#### **Isomap**\n",
    "\n",
    "Isomap\n",
    "\n",
    "reconstruction_error\n",
    "\n",
    "Skipped d=151: There are significant negative eigenvalues (0.000294068 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 161\n",
    "Skipped d=161: There are significant negative eigenvalues (0.0013739 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 171\n",
    "Skipped d=171: There are significant negative eigenvalues (0.00256321 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 181\n",
    "Skipped d=181: There are significant negative eigenvalues (0.00432735 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 191\n",
    "Skipped d=191: There are significant negative eigenvalues (0.00599045 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 201\n",
    "Skipped d=201: There are significant negative eigenvalues (0.00808176 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 211\n",
    "Skipped d=211: There are significant negative eigenvalues (0.0108316 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 221\n",
    "Skipped d=221: There are significant negative eigenvalues (0.0138365 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 231\n",
    "Skipped d=231: There are significant negative eigenvalues (0.0174674 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 241\n",
    "Skipped d=241: There are significant negative eigenvalues (0.0238572 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 251\n",
    "Skipped d=251: There are significant negative eigenvalues (0.0332415 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "Round: 261\n",
    "Skipped d=261: There are significant negative eigenvalues (0.0524513 of the maximum positive). Either the matrix is not PSD, or there was an issue while computing the eigendecomposition of the matrix.\n",
    "\n",
    "#### **Hessian Eigenmapping**\n",
    "\n",
    "For Heissan Eigenmapping the number of neighbords must be greater than $$ \\frac{n \\cdot (n + 3)}{2}$$. Because there are in total 270 data instances, the maximum number of neighbors = n such that $$270 \\leq \\frac{n \\cdot (n + 3)}{2}$$. This formula can be rewritten as $$n^2 + 3n - 540$$ and solved using the quadratic formula as I did below. The maximum components we can use Hessian Eigenmapping for this given dataset is 21 where the number of neighbors is 262.\n",
    "\n",
    "def quadratic_formula(a, b, c):\n",
    "    return (-b + ((b**2 - 4*a*c) **0.5)) / 2*a\n",
    "\n",
    "d = quadratic_formula(1, 3, -540)\n",
    "int(21 * (21 + 4) / 2), d\n",
    "\n",
    "LocallyLinearEmbedding with method set to hessian\n",
    "\n",
    "#### **Modified Locally Linear Kernel**\n",
    "\n",
    "LocallyLinearEmbedding with method set to modified\n",
    "\n",
    "#### **Multidimensional Scaling**\n",
    "\n",
    "MDS dissimilarity='euclidean', normalized_stress='auto'\n",
    "\n",
    "stress_\n",
    "\n",
    "#### **t-Distributed Stochastic Neighbor Embedding**\n",
    "\n",
    "t-SNE cannot expand beyond more than 3 dimensions so that is the maximum set here.\n",
    "\n",
    "coded from scratch but took too long to compute. didn't include sci-kit learn equivalient (for consistency just decided on importing scikit learn packages for everything included personal from scratch code for reference on attempts. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f2923-db70-40d9-a172-ebd425d05f73",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### **Exploratory Data Analysis**\n",
    "\n",
    "#### **Multicollinearity**\n",
    "\n",
    "correlation matrices visualized as heatmaps for parcellation / projection methods that produced less than 30 input features (anything more was harder to visualize but may be considered in the future. Although Logistic Regression \n",
    "\n",
    "make this 1 dataset instead of 3 due to the very low dimesnional input space: & + 3 + 12 = 22 features\n",
    "\n",
    "calculate VIF values, drop features until all VIF < 5 (standard practice) calculate the % of features dropped to see how the parcellation and projection techniques overlap\n",
    "\n",
    "visualize percentages of multicollineratiry in feature extraction methods in bar charts, grouping parcellation methods and dimensionality reduction methods\n",
    "\n",
    "identify which methods produce the most multicollinearity \n",
    "\n",
    "\n",
    "\n",
    "#### **Homogeneity of Variance**\n",
    "levene test for \n",
    "\n",
    "#### Auto correlation\n",
    "\n",
    "plot every feature against the subject variable to see the correlation of each feature to the subject. can see which parcellation/projection techniques are likely to not perform well due to the overdependence on the subject number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a264b192-c510-431a-b7cf-5f85489bafcb",
   "metadata": {},
   "source": [
    "### **Multi-Classification**\n",
    "\n",
    "#### **Hierarchical K-Fold Cross Validation**\n",
    "\n",
    "#### **Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252826e1-b87e-4edc-bc0c-68d264d93905",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### **Results**\n",
    "\n",
    "shows what the top coefficients were for each parcellation method and the magnitude for it was\n",
    "then show which features were the top overall and do some little bit on the research adn waht it likely means\n",
    "\n",
    "relationship between multico and prediction as well as HEV and prediction\n",
    "\n",
    "explain why it makes sense for none of the features from dimensionality reduction methods to be collinear\n",
    "\n",
    "3 tables\n",
    "\n",
    "9 figures\n",
    "- only include tsne for the separability because none of these look separable\n",
    "- also include one where it sows the different 1:1 positive correlaiton relationship of some of the variables to subject number\n",
    "\n",
    "categorize by analysis type and what you learned"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb95db6e-64d3-4a25-9088-e38eed4bc003",
   "metadata": {},
   "source": [
    "### **Conclusion**\n",
    "\n",
    "include the rest of the images i think\n",
    "\n",
    "axes are abstract and harder to map back to brain regions\n",
    "\n",
    "Interpretability: Highly interpretable. If you select \"Activity in left amygdala\" and \"Activity in right prefrontal cortex,\" you know exactly what each axis represents in physiological terms.\n",
    "\n",
    "mean averages across categories and then feeding that into a model may be better than we think\n",
    "\n",
    "#### Future Work\n",
    "\n",
    "train the model without subject included\n",
    "\n",
    "Laplacian Eigenmaps as done in [D]\n",
    "\n",
    "```\n",
    "BEFOREEE\n",
    "\n",
    "\n",
    "```\n",
    "neater organization of files\n",
    "- separate test and train and parcellation and projections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d31fd7-151d-4c5d-9ed4-22dad87a00ff",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### **Appendix**\n",
    "\n",
    "include the rest of the images i think"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704eebf3-cb18-4862-b362-163c6cd46d60",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "source": [
    "### **Acknowledgements**\n",
    "\n",
    "Thank you to Professor Ahmad for a great semester!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7b62a5-72c2-4752-b757-5398d04ddea8",
   "metadata": {},
   "source": [
    "### **Reference**\n",
    "\n",
    "Works Cited\n",
    "\n",
    "Abraham, A., Pedregosa, F., Eickenberg, M., Gervais, P., Mueller, A., Kossaifi, J., & Varoquaux, G. (2014). Machine learning for neuroimaging with scikit-learn. Frontiers in neuroinformatics, 8, 14.\n",
    "\n",
    "Pereira, F., Mitchell, T., & Botvinick, M. (2009). Machine learning classifiers and fMRI: a tutorial overview. Neuroimage, 45(1), S199-S209."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
