{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a319bbda-7b84-4e52-9c4a-c589e89e2b45",
   "metadata": {},
   "source": [
    "## **Inside Out ML: Emotion Classification from fMRI Using Parcellation and Projection Techniques**\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./cover-img.png\" alt=\"image\" width=\"600\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74dbbf6b-90b1-40d6-99f4-de0223367b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anandafrancis/opt/anaconda3/lib/python3.8/site-packages/nilearn/datasets/__init__.py:93: FutureWarning: Fetchers from the nilearn.datasets module will be updated in version 0.9 to return python strings instead of bytes and Pandas dataframes instead of Numpy arrays.\n",
      "  warn(\"Fetchers from the nilearn.datasets module will be \"\n"
     ]
    }
   ],
   "source": [
    "from itertools import product\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib import colormaps\n",
    "import nibabel as nib\n",
    "from nilearn import input_data, plotting\n",
    "from nilearn import datasets as ni_data\n",
    "from nilearn.image import get_data\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pandas.errors import PerformanceWarning\n",
    "from pprint import pprint as pp\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cdist\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.manifold import Isomap, MDS, LocallyLinearEmbedding, TSNE\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor as vif\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets as torch_data\n",
    "import warnings\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250e71ec-dbc7-4f60-bb22-4c2ca41b1181",
   "metadata": {},
   "source": [
    "# **Load Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80794c9b-6209-4c91-ae18-149d75a328ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_list(subs, emotions, primings):\n",
    "    '''\n",
    "    purpose: create lists for file names, specified subjects, emotion states and priming conditions\n",
    "    \n",
    "    parameters:\n",
    "        subs: list: subject numbers\n",
    "        emotions: list: emotion states (anger, fear, disgust)\n",
    "        priming: list: of priming conditions (congruent,, incongruent, neutral)\n",
    "    \n",
    "    output: \n",
    "        files (list): list of file names\n",
    "        subject_no (list): list of subject numbers matching the order of the file names\n",
    "        emotion_class (list): list of emotion states matching the order of the file names\n",
    "        priming_class (list): list of priming conditions matching the order of the file names\n",
    "        \n",
    "    '''\n",
    "\n",
    "    # intialize vars\n",
    "    files = []\n",
    "    subject_no = []\n",
    "    emotion_class = []\n",
    "    priming_class = []\n",
    "\n",
    "    # iterate over the different classes\n",
    "    for sub in subs:\n",
    "        for emo in emotions: \n",
    "            for priming in primings:\n",
    "    \n",
    "                # get the subject as a string\n",
    "                if sub // 10 == 0:\n",
    "                    sub_str = '00' + str(sub)\n",
    "                else:\n",
    "                    sub_str = '0' + str(sub)\n",
    "                \n",
    "                # create the filename and add to list\n",
    "                filename = './emotion-fmri-neu/cp' + sub_str + '_beta_' + emo + '_' + priming + '_c0.nii.gz'\n",
    "                files.append(filename)\n",
    "                subject_no.append(sub)\n",
    "                emotion_class.append(emo)\n",
    "                priming_class.append(priming)\n",
    "\n",
    "    return files, subject_no, emotion_class, priming_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cbae8b2-7de4-4b60-96e8-ce00ffeb408f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(files):\n",
    "    '''\n",
    "    purpose: generate dataset of image_da tuple of file names, specified subjects, emotion states and priming conditions\n",
    "    \n",
    "    parameters:\n",
    "        none\n",
    "    \n",
    "    output: \n",
    "        image_data: np.array: 4D array of voxel brain data for 270 test subjects\n",
    "    '''\n",
    "\n",
    "    # convert image data to NumPy array\n",
    "    image_list = []\n",
    "\n",
    "    for f in files:\n",
    "        img = nib.load(f)\n",
    "        data = img.get_fdata()\n",
    "        image_list.append(data)\n",
    "\n",
    "    # stack all into one 4D array: (270, 91, 109, 91)\n",
    "    image_data = np.stack(image_list)\n",
    "\n",
    "    return image_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0b18d541-a6df-42f2-aee2-2379c3a109d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 91, 109, 91)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create lists for classes and filenames\n",
    "subjects = range(1,31)\n",
    "emotions = ['anger', 'fear', 'disgust']\n",
    "primings = ['congruent', 'incongruent', 'neutral']\n",
    "files, subject_no, emotion_class, priming_class = create_file_list(subjects, emotions, primings)\n",
    "\n",
    "# load raw data as numpy arrays\n",
    "image_data  = create_dataset(files)\n",
    "\n",
    "# output dimension to understand underlying data structure\n",
    "image_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b0eb065a-dc73-4c04-8b24-b7010b045727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'data' already exists.\n",
      "Directory './data/parcellations' already exists.\n",
      "Directory './data/collinearity' already exists.\n",
      "Directory './data/bivariate_data' already exists.\n",
      "Directory './data/cost_function_logs' already exists.\n",
      "Directory './data/projections' already exists.\n",
      "Directory './data/interpretation' already exists.\n",
      "Directory './data/autocorrelation' created successfully.\n",
      "Directory './data/heteroscedasticity' already exists.\n",
      "Directory './data/models' already exists.\n",
      "Directory './data/log_reg_results' already exists.\n",
      "Directory './data/log_reg_results/classification_reports' already exists.\n",
      "Directory './data/log_reg_results/coefficients' already exists.\n",
      "Directory './data/log_reg_results/errors' already exists.\n",
      "Directory './data/log_reg_results/metrics' already exists.\n",
      "Directory './data/log_reg_results/confusion_matrices' already exists.\n",
      "Directory 'visualizations' already exists.\n",
      "Directory './visualizations/cost_functions' already exists.\n",
      "Directory './visualizations/collinearity' already exists.\n",
      "Directory './visualizations/atlas_maps' already exists.\n",
      "Directory './visualizations/heteroscedasticity' already exists.\n",
      "Directory './visualizations/bivariate_data' already exists.\n",
      "Directory './visualizations/autocorrelation' already exists.\n",
      "Directory './visualizations/bivariate_data/subject' already exists.\n",
      "Directory './visualizations/bivariate_data/emotion' already exists.\n",
      "Directory './visualizations/bivariate_data/priming' already exists.\n"
     ]
    }
   ],
   "source": [
    "# create directories to load data outputs into\n",
    "directories = [ 'data', \n",
    "                   './data/parcellations', \n",
    "                   './data/collinearity',\n",
    "                   './data/bivariate_data',\n",
    "                   './data/cost_function_logs',\n",
    "                   './data/projections',\n",
    "                   './data/interpretation',\n",
    "                   './data/autocorrelation',\n",
    "                   './data/heteroscedasticity',\n",
    "                   './data/models',\n",
    "                   './data/log_reg_results',\n",
    "                          './data/log_reg_results/classification_reports',\n",
    "                          './data/log_reg_results/coefficients',\n",
    "                          './data/log_reg_results/errors',\n",
    "                          './data/log_reg_results/metrics',\n",
    "                           './data/log_reg_results/confusion_matrices',\n",
    "                           \n",
    "               'visualizations', \n",
    "                   './visualizations/cost_functions', \n",
    "                   './visualizations/collinearity',\n",
    "                   './visualizations/atlas_maps', \n",
    "                   './visualizations/heteroscedasticity', \n",
    "                   './visualizations/bivariate_data',\n",
    "                   './visualizations/autocorrelation',\n",
    "                   './visualizations/bivariate_data/subject',\n",
    "                   './visualizations/bivariate_data/emotion',\n",
    "                   './visualizations/bivariate_data/priming',\n",
    "              ]\n",
    "\n",
    "for dir_name in directories:\n",
    "    try:\n",
    "        os.mkdir(dir_name)\n",
    "        print(f\"Directory '{dir_name}' created successfully.\")\n",
    "    except FileExistsError:\n",
    "        print(f\"Directory '{dir_name}' already exists.\")\n",
    "    except PermissionError:\n",
    "        print(f\"Permission denied: Unable to create '{dir_name}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3c4e71-d9b5-4a46-b420-a038264a03d0",
   "metadata": {},
   "source": [
    "## **Brain Parcellations Methods (Atlas Maps from Nilearn.datasets)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53912aa6-800d-4a4f-8ec8-8c418356359e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcellation_atlas_dict():\n",
    "    \n",
    "    '''\n",
    "    purpose: create a dictionaries for all parcellation techniques with their respective maps and labels\n",
    "    parameters: none\n",
    "    output: \n",
    "        tuple: \n",
    "            maps: dict: brain parcellation atlas maps in the NiLearn dataset  \n",
    "            regions: dict: brain regions correlated to each map  \n",
    "    '''\n",
    "\n",
    "    # Harvard Oxford Atlases\n",
    "    harvard_oxford_cort_0_1 = ni_data.fetch_atlas_harvard_oxford('cort-maxprob-thr0-1mm')\n",
    "    harvard_oxford_cortl_0_1 = ni_data.fetch_atlas_harvard_oxford('cortl-maxprob-thr0-1mm')\n",
    "    harvard_oxford_sub_0_1 = ni_data.fetch_atlas_harvard_oxford('sub-maxprob-thr0-1mm')\n",
    "\n",
    "    # Juelich Atlas\n",
    "    juelich_0_1 = ni_data.fetch_atlas_juelich('maxprob-thr0-1mm')\n",
    "\n",
    "    # AAL templates\n",
    "    aal_spm12 = ni_data.fetch_atlas_aal('SPM12')\n",
    "\n",
    "    # Talairach atlases\n",
    "    talairach_hemi = ni_data.fetch_atlas_talairach('hemisphere')\n",
    "    talairach_lobe = ni_data.fetch_atlas_talairach('lobe')\n",
    "    talairach_gyrus = ni_data.fetch_atlas_talairach('gyrus')\n",
    "    talairach_tissue = ni_data.fetch_atlas_talairach('tissue')\n",
    "    talairach_ba = ni_data.fetch_atlas_talairach('ba')\n",
    "\n",
    "    # Schaefer 2018 atlas\n",
    "    schaefer_100_7_1 = ni_data.fetch_atlas_schaefer_2018(n_rois=100, yeo_networks=7, resolution_mm=1)\n",
    "\n",
    "    maps = {\n",
    "              'Harvard_Oxford cort 0 x 1': harvard_oxford_cort_0_1.maps, 'Harvard_Oxford cortl 0 x 1': harvard_oxford_cortl_0_1.maps,\n",
    "              'Harvard_Oxford sub 0 x 1': harvard_oxford_sub_0_1.maps, 'Juelich 0 x 1' : juelich_0_1.maps, 'AAL SPM12' : aal_spm12.maps,\n",
    "               'Talairach Hemi' : talairach_hemi.maps, 'Talairach Lobe' : talairach_lobe.maps, 'Talairach Gyrus' : talairach_gyrus.maps,\n",
    "               'Talairach Tissue' : talairach_tissue.maps, 'Talairach Ba' : talairach_ba.maps,\n",
    "              'Schaefer 100 x 7 x 1' : schaefer_100_7_1.maps,\n",
    "            }\n",
    "\n",
    "\n",
    "    regions = {\n",
    "              'Harvard_Oxford cort 0 x 1': harvard_oxford_cort_0_1.labels, 'Harvard_Oxford cortl 0 x 1': harvard_oxford_cortl_0_1.labels,\n",
    "              'Harvard_Oxford sub 0 x 1': harvard_oxford_sub_0_1.labels, 'Juelich 0 x 1' : juelich_0_1.labels, 'AAL SPM12' : aal_spm12.labels,\n",
    "               'Talairach Hemi' : talairach_hemi.labels, 'Talairach Lobe' : talairach_lobe.labels, 'Talairach Gyrus' : talairach_gyrus.labels,\n",
    "               'Talairach Tissue' : talairach_tissue.labels, 'Talairach Ba' : talairach_ba.labels,\n",
    "              'Schaefer 100 x 7 x 1' : schaefer_100_7_1.labels,\n",
    "            }\n",
    "\n",
    "    return maps, regions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c441eeea-f044-41ec-8ead-a324724cda32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parcellized_brain_vecs(brain_imgs, parc_map, atlas):\n",
    "    '''\n",
    "    purpose: transform each .nii.gz image into a 1D vector using brain parcellation techniques\n",
    "    \n",
    "    params:\n",
    "        brain_img: list: filenames for fMRI data\n",
    "        parc_map : dict: dictionary of parcellation atlas maps\n",
    "        atlas : str: name of brain parcellation technique\n",
    "\n",
    "    \n",
    "    output: np.array: transformed data based on input parcellation technique\n",
    "    '''\n",
    "    #  get atlas map to overlay and extract ROI values\n",
    "    masker = input_data.NiftiLabelsMasker(labels_img=parc_map[atlas])\n",
    "\n",
    "    # transformed into 1D feature vectors for each ROI\n",
    "    features = masker.fit_transform(brain_imgs)\n",
    "    \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4126d479-6c58-4944-ad0a-c93eb45cf83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets for each brain parcellation\n",
    "maps, regions = parcellation_atlas_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4ed0da1-180d-400d-8f1d-47f9a6942a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as csv files for output-only codebase (kernel often dies during workflow codebase)\n",
    "for key in maps.keys():\n",
    "    data = parcellized_brain_vecs(files, maps, key)\n",
    "\n",
    "    # skip 'Background' label for some atlases\n",
    "    if (key == 'AAL SPM12') or (key == 'Schaefer 100 x 7 x 1'):\n",
    "        names = regions[key]\n",
    "    else:\n",
    "        names = regions[key][1:]\n",
    "    df = pd.DataFrame(data, columns=names)\n",
    "    df['filename'] = files\n",
    "    df['subject'] = subject_no\n",
    "    df['emotion'] = emotion_class\n",
    "    df['priming'] = priming_class\n",
    "    df.to_csv(f'./data/parcellations/{key}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3f3b0e-9873-4134-abaa-fb5ec43af649",
   "metadata": {},
   "source": [
    "## **Dimensionality Reduction Methods (PCA & Non-Linear Manifolds)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "318871d5-aa33-42a4-8398-0e034b7e05bd",
   "metadata": {},
   "source": [
    "    class Autoencoder(nn.Module):\n",
    "        \"\"\"Autoencoder implementation using PyTorch\"\"\"\n",
    "        def __init__(self, input_dim, latent_dim=2):\n",
    "            super(Autoencoder, self).__init__()\n",
    "            self.encoder = nn.Sequential(\n",
    "                nn.Linear(input_dim, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, latent_dim)\n",
    "            )\n",
    "            self.decoder = nn.Sequential(\n",
    "                nn.Linear(latent_dim, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 256),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(256, input_dim),\n",
    "                nn.Sigmoid()\n",
    "            )\n",
    "        \n",
    "        def forward(self, x):\n",
    "            encoded = self.encoder(x)\n",
    "            decoded = self.decoder(encoded)\n",
    "            return decoded\n",
    "        \n",
    "        def encode(self, x):\n",
    "            return self.encoder(x)\n",
    "\n",
    "    def train_autoencoder(X, input_dim, latent_dim=2, epochs=50, batch_size=128):\n",
    "        \"\"\"Train autoencoder and return latent representations\"\"\"\n",
    "        model = Autoencoder(input_dim, latent_dim)\n",
    "        criterion = nn.MSELoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        \n",
    "        #Convert to PyTorch tensors\n",
    "        X_tensor = torch.FloatTensor(X)\n",
    "        dataset = torch.utils.data.TensorDataset(X_tensor, X_tensor)\n",
    "        dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "        \n",
    "        #Training loop\n",
    "        for epoch in range(epochs):\n",
    "            for batch_features, _ in dataloader:\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(batch_features)\n",
    "                loss = criterion(outputs, batch_features)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "        \n",
    "        #Get latent representations\n",
    "        with torch.no_grad():\n",
    "            latent = model.encode(X_tensor).numpy()\n",
    "        \n",
    "        return latent\n",
    "\n",
    "    def sammon_mapping(x, n = 2, display = 0, inputdist = 'raw', maxhalves = 20, maxiter = 500, tolfun = 1e-9, init = 'pca'):\n",
    "        '''from open source contirbutor: https://pypi.org/project/sammon-mapping'''\n",
    "        \n",
    "        X = x\n",
    "    \n",
    "        # Create distance matrix unless given by parameters\n",
    "        if inputdist == 'distance':\n",
    "            xD = X\n",
    "        else:\n",
    "            xD = cdist(X, X)\n",
    "    \n",
    "        # Remaining initialisation\n",
    "        N = X.shape[0] # hmmm, shape[1]?\n",
    "        scale = 0.5 / xD.sum()\n",
    "    \n",
    "        if init == 'pca':\n",
    "            [UU,DD,_] = np.linalg.svd(X)\n",
    "            Y = UU[:,:n]*DD[:n] \n",
    "        else:\n",
    "            Y = np.random.normal(0.0,1.0,[N,n])\n",
    "        one = np.ones([N,n])\n",
    "    \n",
    "        xD = xD + np.eye(N)        \n",
    "        xDinv = 1 / xD # Returns inf where D = 0.\n",
    "        xDinv[np.isinf(xDinv)] = 0 # Fix by replacing inf with 0 (default Matlab behaviour).    \n",
    "        yD = cdist(Y, Y) + np.eye(N)\n",
    "        yDinv = 1. / yD # Returns inf where d = 0. \n",
    "        \n",
    "        np.fill_diagonal(xD, 1)    \n",
    "        np.fill_diagonal(yD, 1)\n",
    "        np.fill_diagonal(xDinv, 0)\n",
    "        np.fill_diagonal(yDinv, 0)\n",
    "        \n",
    "        xDinv[np.isnan(xDinv)] = 0\n",
    "        yDinv[np.isnan(xDinv)] = 0\n",
    "        xDinv[np.isinf(xDinv)] = 0    \n",
    "        yDinv[np.isinf(yDinv)] = 0 # Fix by replacing inf with 0 (default Matlab behaviour).\n",
    "        \n",
    "        delta = xD - yD \n",
    "        E = ((delta**2)*xDinv).sum() \n",
    "    \n",
    "        # Get on with it\n",
    "        for i in range(maxiter):\n",
    "    \n",
    "            # Compute gradient, Hessian and search direction (note it is actually\n",
    "            # 1/4 of the gradient and Hessian, but the step size is just the ratio\n",
    "            # of the gradient and the diagonal of the Hessian so it doesn't\n",
    "            # matter).\n",
    "            delta = yDinv - xDinv\n",
    "            deltaone = np.dot(delta,one)\n",
    "            g = np.dot(delta, Y) - (Y * deltaone)\n",
    "            dinv3 = yDinv ** 3\n",
    "            y2 = Y ** 2\n",
    "            H = np.dot(dinv3,y2) - deltaone - np.dot(2, Y) * np.dot(dinv3, Y) + y2 * np.dot(dinv3,one)\n",
    "            s = -g.flatten(order='F') / np.abs(H.flatten(order='F'))\n",
    "            y_old = Y\n",
    "    \n",
    "            # Use step-halving procedure to ensure progress is made\n",
    "            for j in range(maxhalves):\n",
    "                s_reshape = s.reshape(2,round(len(s)/2)).T\n",
    "                y = y_old + s_reshape\n",
    "                d = cdist(y, y) + np.eye(N)\n",
    "                dinv = 1 / d # Returns inf where D = 0. \n",
    "                dinv[np.isinf(dinv)] = 0 # Fix by replacing inf with 0 (default Matlab behaviour).\n",
    "                delta = xD - d\n",
    "                E_new = ((delta**2)*xDinv).sum()\n",
    "                if E_new < E:\n",
    "                    break\n",
    "                else:\n",
    "                    s = np.dot(0.5,s)\n",
    "    \n",
    "            # Bomb out if too many halving steps are required\n",
    "            if j == maxhalves:\n",
    "                print('Warning: maxhalves exceeded. Sammon mapping may not converge...')\n",
    "    \n",
    "            # Evaluate termination criterion\n",
    "            if np.abs((E - E_new) / E) < tolfun:\n",
    "                if display:\n",
    "                    print('TolFun exceeded: Optimisation terminated')\n",
    "                break\n",
    "    \n",
    "            # Report progress\n",
    "            E = E_new\n",
    "            if display > 1:\n",
    "                print('epoch = ' + str(i) + ': E = ' + str(E * scale))\n",
    "    \n",
    "            # Fiddle stress to match te original Sammon paper\n",
    "            E = E * scale\n",
    "        \n",
    "        return y,E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3820ded3-65d5-4137-9300-f2d77d2a9e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 902629)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape and scale each image from 3D to 1D\n",
    "X = StandardScaler().fit_transform(image_data.reshape(270, -1))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc34860c-1b90-4de5-8911-cb9ed27836b4",
   "metadata": {},
   "source": [
    "### **Principal Component Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe12a10-66db-48db-ad6b-0a9c982b199b",
   "metadata": {},
   "source": [
    "    class PCA:\n",
    "        def __init__(self, n_components=2):\n",
    "            self.n_components = n_components\n",
    "            self.components = None\n",
    "            self.mean = None\n",
    "        \n",
    "        def fit(self, X):\n",
    "            # Center the data\n",
    "            self.mean = np.mean(X, axis=0)\n",
    "            X_centered = X - self.mean\n",
    "            \n",
    "            #Compute covariance matrix\n",
    "            cov_matrix = np.cov(X_centered.T)\n",
    "            \n",
    "            #Compute eigenvalues and eigenvectors\n",
    "            eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)\n",
    "            \n",
    "            #Sort eigenvectors by eigenvalues in descending order\n",
    "            sorted_idx = np.argsort(eigenvalues)[::-1]\n",
    "            self.components = eigenvectors[:, sorted_idx][:, :self.n_components]\n",
    "            \n",
    "            #Explained variance\n",
    "            self.explained_variance = eigenvalues[sorted_idx][:self.n_components]\n",
    "            self.explained_variance_ratio = self.explained_variance / np.sum(eigenvalues)\n",
    "            \n",
    "            return self\n",
    "        \n",
    "        def transform(self, X):\n",
    "            if self.mean is None or self.components is None:\n",
    "                raise RuntimeError(\"PCA must be fitted before transforming data\")\n",
    "            X_centered = X - self.mean\n",
    "            return np.dot(X_centered, self.components)\n",
    "        \n",
    "        def fit_transform(self, X):\n",
    "            self.fit(X)\n",
    "            return self.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c85c4c99-bd4c-432d-9e20-ce9d9a9654f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of components to explain 99% of variance: 226\n"
     ]
    }
   ],
   "source": [
    "# fit PCA model\n",
    "pca = PCA()\n",
    "X_test_pca = pca.fit_transform(X)\n",
    "\n",
    "# get cumulative explained variance\n",
    "cumulative_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "\n",
    "# plot explained variance over component count \n",
    "plt.figure(figsize=(9, 6))\n",
    "plt.plot(cumulative_variance)\n",
    "plt.axhline(y=0.99, color='r', linestyle='--')\n",
    "\n",
    "plt.xlabel('Number of components')\n",
    "plt.ylabel('Cumulative explained variance')\n",
    "plt.title('Explained Variance vs. Components')\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.savefig(\"./visualizations/cost_functions/PCA.png\")\n",
    "plt.close()\n",
    "\n",
    "# find the number of components that reach 99% variance\n",
    "n_components_99 = np.argmax(cumulative_variance >= 0.99) + 1\n",
    "print(f\"Number of components to explain 99% of variance: {n_components_99}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85200bcf-92a7-4bfc-a53e-9355bb7349dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA dim reduction with 226 components\n",
    "pca_dim_redux = PCA(n_components=226)\n",
    "X_pca = pca_dim_redux.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe34fd-4b3f-4297-b57b-c8448a8e0e90",
   "metadata": {},
   "source": [
    "### **Stress Functions and Reconstruction Errors**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a303dfaa-ec4e-4ff7-a555-11e45665cc92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_function_per_component(model, input_data, max_dims=269):\n",
    "\n",
    "    # initialize\n",
    "    errors = {}\n",
    "    log_file = f\"./data/cost_function_logs/{model}.txt\"\n",
    "\n",
    "    with open(log_file, \"w\") as log:\n",
    "\n",
    "        # iterate over every 5 for speed\n",
    "        for d in range(1, max_dims, 5):\n",
    "\n",
    "            # track the number of components\n",
    "            log.write(f\"Round: {d}\\n\")\n",
    "            \n",
    "            try:\n",
    "                if model == 'sammon':\n",
    "                    output, E = sammon_mapping(input_data, d)\n",
    "                    errors[d] = E\n",
    "                elif model == 'isomap':\n",
    "                    isomap = Isomap(n_components=d, n_neighbors=10)\n",
    "                    X_iso = isomap.fit_transform(input_data)\n",
    "                    E = isomap.reconstruction_error()\n",
    "                    errors[d] = E\n",
    "                elif model == 'mlle':\n",
    "                    embedding = LocallyLinearEmbedding(n_components=d, method='modified', n_neighbors=d * 2)\n",
    "                    X_transformed = embedding.fit_transform(input_data)\n",
    "                    E = embedding.reconstruction_error_\n",
    "                    errors[d] = E\n",
    "                elif model == 'hessian':\n",
    "                    embedding = LocallyLinearEmbedding(n_components=d, method='hessian', n_neighbors=int(d * (d + 4) / 2))\n",
    "                    X_transformed = embedding.fit_transform(input_data)\n",
    "                    E = embedding.reconstruction_error_\n",
    "                    errors[d] = E\n",
    "                elif model == 'mds':\n",
    "                    mds = MDS(n_components=d, dissimilarity='euclidean', normalized_stress='auto')\n",
    "                    X_mapped = mds.fit_transform(input_data)\n",
    "                    E = mds.stress_\n",
    "                    errors[d] = E\n",
    "\n",
    "                log.write(f\"Components: {d}, Error: {E}\\n\\n\")\n",
    "\n",
    "            # store errors and the number of components\n",
    "            except ValueError as e:\n",
    "                log.write(f\"Skipped d={d}: {e}\\n\\n\")\n",
    "                continue\n",
    "\n",
    "    # plot the cost function\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    keys = list(errors.keys())\n",
    "    vals = list(errors.values())\n",
    "    plt.plot(keys, vals)\n",
    "\n",
    "    plt.xlabel('Number of components')\n",
    "    plt.ylabel('Error')\n",
    "    plt.title(f'Cost Function vs. Components ({model})')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.xticks(range(min(keys), max(keys) + 1, 5), rotation=45)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f\"./visualizations/cost_functions/{model}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f0e2b-6db4-4479-bc05-0676e2fa62a2",
   "metadata": {},
   "source": [
    "### **Isomap**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fa0ade9-503b-4c58-a6d5-b06ccd42854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_function_per_component('isomap', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6ea106a2-bbd9-4e00-ab52-af4bfb880914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Isomap dim reduction with 51 components, neighbors set to 45\n",
    "isomap_dim_redux = Isomap(n_components=51, n_neighbors=55)\n",
    "X_isomap = isomap_dim_redux.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a82752-7d9e-4add-a943-f6278f1af87a",
   "metadata": {},
   "source": [
    "### **t-SNE**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d45a10-1fae-4896-b9d4-dafd5e0898c8",
   "metadata": {},
   "source": [
    "    class TSNE:\n",
    "        def __init__(self, n_components=2, perplexity=30.0, learning_rate=200.0, \n",
    "                     max_iter=1000, early_exaggeration=4, verbose=False):\n",
    "            self.n_components = n_components\n",
    "            self.perplexity = perplexity\n",
    "            self.learning_rate = learning_rate\n",
    "            self.max_iter = max_iter\n",
    "            self.early_exaggeration = early_exaggeration\n",
    "            self.verbose = verbose\n",
    "        \n",
    "        def _Hbeta(self, D, beta=1.0):\n",
    "            \"\"\"Compute H and P for a given beta (precision)\"\"\"\n",
    "            P = np.exp(-D * beta)\n",
    "            sumP = np.sum(P)\n",
    "            H = np.log(sumP) + beta * np.sum(D * P) / sumP\n",
    "            P = P / sumP\n",
    "            return H, P\n",
    "        \n",
    "        def _x2p(self, X):\n",
    "            \"\"\"Compute pairwise affinities for t-SNE\"\"\"\n",
    "            (n, d) = X.shape\n",
    "            sum_X = np.sum(np.square(X), 1)\n",
    "            D = np.add(np.add(-2 * np.dot(X, X.T), sum_X).T , sum_X)\n",
    "            P = np.zeros((n, n))\n",
    "            beta = np.ones((n, 1))\n",
    "            logU = np.log(self.perplexity)\n",
    "            \n",
    "            #Binary search to find beta that produces target perplexity\n",
    "            for i in range(n):\n",
    "                betamin = -np.inf\n",
    "                betamax = np.inf\n",
    "                Di = D[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))]\n",
    "                H, thisP = self._Hbeta(Di, beta[i])\n",
    "                Hdiff = H - logU\n",
    "                tries = 0\n",
    "                while np.abs(Hdiff) > 1e-5 and tries < 50:\n",
    "                    if Hdiff > 0:\n",
    "                        betamin = beta[i].copy()\n",
    "                        if betamax == np.inf:\n",
    "                            beta[i] = beta[i] * 2\n",
    "                        else:\n",
    "                            beta[i] = (beta[i] + betamax) / 2\n",
    "                    else:\n",
    "                        betamax = beta[i].copy()\n",
    "                        if betamin == -np.inf:\n",
    "                            beta[i] = beta[i] / 2\n",
    "                        else:\n",
    "                            beta[i] = (beta[i] + betamin) / 2\n",
    "                    \n",
    "                    H, thisP = self._Hbeta(Di, beta[i])\n",
    "                    Hdiff = H - logU\n",
    "                    tries += 1\n",
    "                \n",
    "                P[i, np.concatenate((np.r_[0:i], np.r_[i+1:n]))] = thisP\n",
    "            return P\n",
    "        \n",
    "        def fit_transform(self, X):\n",
    "            \"\"\"Fit t-SNE model and return transformed data\"\"\"\n",
    "            (n, _) = X.shape\n",
    "            \n",
    "            #Initialize Y randomly\n",
    "            Y = np.random.randn(n, self.n_components)\n",
    "            dY = np.zeros((n, self.n_components))\n",
    "            iY = np.zeros((n, self.n_components))\n",
    "            gains = np.ones((n, self.n_components))\n",
    "            \n",
    "            #Compute P-values\n",
    "            P = self._x2p(X)\n",
    "            P = P + np.transpose(P)\n",
    "            P = P / np.sum(P)\n",
    "            P = P * self.early_exaggeration\n",
    "            P = np.maximum(P, 1e-12)\n",
    "            \n",
    "            #Run iterations\n",
    "            for iter in range(self.max_iter):\n",
    "                #Compute Q-values (Student-t distribution)\n",
    "                sum_Y = np.sum(np.square(Y), 1)\n",
    "                num = 1 / (1 + np.add(np.add(-2 * np.dot(Y, Y.T), sum_Y).T , sum_Y))\n",
    "                num[range(n), range(n)] = 0\n",
    "                Q = num / np.sum(num)\n",
    "                Q = np.maximum(Q, 1e-12)\n",
    "                \n",
    "                #Compute gradient\n",
    "                PQ = P - Q\n",
    "                for i in range(n):\n",
    "                    dY[i, :] = np.sum(np.tile(PQ[:, i] * num[:, i], (self.n_components, 1)).T * (Y[i, :] - Y), 0)\n",
    "                \n",
    "                #Perform the update\n",
    "                if iter < 20:\n",
    "                    momentum = 0.5\n",
    "                else:\n",
    "                    momentum = 0.8\n",
    "                gains = (gains + 0.2) * ((dY > 0) != (iY > 0)) + (gains * 0.8) * ((dY > 0) == (iY > 0))\n",
    "                gains[gains < 0.01] = 0.01\n",
    "                iY = momentum * iY - self.learning_rate * (gains * dY)\n",
    "                Y = Y + iY\n",
    "                Y = Y - np.tile(np.mean(Y, 0), (n, 1))\n",
    "                \n",
    "                #Stop early exaggeration after 100 iterations\n",
    "                if iter == 100:\n",
    "                    P = P / self.early_exaggeration\n",
    "                \n",
    "                #Progress output\n",
    "                if self.verbose and (iter + 1) % 100 == 0:\n",
    "                    C = np.sum(P * np.log(P / Q))\n",
    "                    print(f\"Iteration {iter + 1}: error is {C}\")\n",
    "            \n",
    "            return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "923da936-d8c4-4e5e-897b-cdccbb348b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tsne = TSNE(n_components=3, learning_rate='auto', init='random', perplexity=3).fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6c6adb-a0bb-4098-83fd-39bc8fe911b1",
   "metadata": {},
   "source": [
    "### **Hessian Eigenmapping**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc9d6262-388d-43c7-9e44-5e89a58c90b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(271, 21.786262044390035)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def quadratic_formula(a, b, c):\n",
    "    return (-b + ((b**2 - 4*a*c) **0.5)) / 2*a\n",
    "\n",
    "# hessian eigenmapping component count c is restricted to neighbors = (c * (c + 3) / 2)\n",
    "c = quadratic_formula(1, 3, -540)\n",
    "int((c * (c + 3) / 2) + 1), c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31175556-7c61-4bce-88ac-acf0ca3334ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Hessian Eigenmapping dim reduction with 21 components (and all possible neighbors)\n",
    "hessian_dim_redux = LocallyLinearEmbedding(n_components=21, method='hessian', n_neighbors=269)\n",
    "X_hessian= hessian_dim_redux.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb06bf2-d6e0-4ea3-b126-9119d33c449e",
   "metadata": {},
   "source": [
    "### **Multi-dimesional Scaling**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b38900b-bb49-405b-94ef-99ecb54aefae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_cost_function_per_component('mds', X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "05947f71-6eaa-4d47-a5e0-0ae40ffca944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MDS dim reduction with 50 components\n",
    "mds_dim_redux = MDS(n_components=5, dissimilarity='euclidean', normalized_stress='auto')\n",
    "X_mds = mds_dim_redux.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f675006-40a5-49da-bafb-bb1c1c5604bd",
   "metadata": {},
   "source": [
    "## **Reduce Data Dimensions and Store New Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "49fb0d36-9ab9-4518-b991-cb814462a7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for datasets of each dimension reduction method\n",
    "projection_dict = {'PCA': X_pca, 'Isomap': X_isomap, 'Hessian': X_hessian, 'MDS': X_mds, 't-SNE': X_tsne }\n",
    "projection_methods = ['PCA', 'Isomap', 'Hessian', 'MDS', 't-SNE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2234ac4-d306-4c81-aaa0-db7af4ed74c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data as csv files for output-only codebase (kernel often dies during workflow codebase)\n",
    "for key in projection_methods:\n",
    "    data = projection_dict[key]\n",
    "    names = [f'Feat {i+1}' for i in range(len(data.T))]\n",
    "    df = pd.DataFrame(data, columns=names)\n",
    "    df['filename'] = files\n",
    "    df['subject'] = subject_no\n",
    "    df['emotion'] = emotion_class\n",
    "    df['priming'] = priming_class\n",
    "    df.to_csv(f'./data/projections/{key}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95050213-a03d-4ad6-bd1f-0f8152b00033",
   "metadata": {},
   "source": [
    "# **Exploratory Data Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "367896b7-4260-44ab-be4f-66fb2a083e07",
   "metadata": {},
   "source": [
    "## **Load New Datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ed19ed85-e5df-4fa8-ae39-7d3f33901767",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PCA', 'Isomap', 'Hessian', 'MDS', 't-SNE']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "projection_methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aaa803d-8894-40ed-ae06-2cf09ae2889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "parcellations = {key: pd.read_csv(f'./data/parcellations/{key}.csv') for key in maps.keys()}\n",
    "projections = {key: pd.read_csv(f'./data/projections/{key}.csv') for key in projection_methods}\n",
    "\n",
    "# make this 1 dataset instead of 3 due to the very low dimesnional input space: & + 3 + 12 = 22 features\n",
    "parcellations['Talairach Hemi x Lobe x Tissue'] = parcellations['Talairach Hemi'].merge(\n",
    "    parcellations['Talairach Lobe'], how='outer', on=['subject', 'priming', 'filename', 'emotion']).merge(\n",
    "    parcellations['Talairach Tissue'], how='outer', on=['subject', 'priming', 'filename', 'emotion'])\n",
    "\n",
    "parcellations['Talairach Hemi x Lobe x Tissue'].to_csv('./data/parcellations/Talairach Hemi x Lobe x Tissue.csv', index=False)\n",
    "\n",
    "parcellation_methods = parcellations.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b6904ab-cd7a-46f6-b027-e2842462a802",
   "metadata": {},
   "source": [
    "## **Brain Parcellation Visuals**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "24941a86-5d36-45ee-8c92-ed328a409b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_parcellation_map(atlas, maps, cut_coords = (3,-30,13)):\n",
    "    '''\n",
    "    purpose: plot visualization to show the areas of the brain divivded in parcellation atlas\n",
    "        \n",
    "    params:\n",
    "        atlas_name : str: Name of brain parcellation technique  \n",
    "        atlas_types : dict: Dictionary of parcellation atlases and their maps and labels   \n",
    "        cut_coords : tuple Coordinates for brain visualization\n",
    "    \n",
    "    output: none, displays visualization of brain data\n",
    "    '''\n",
    "    \n",
    "    atlas_map = maps[atlas]\n",
    "    \n",
    "    if type(atlas_map) == tuple:\n",
    "        atlas_map = atlas_map[0]\n",
    "    \n",
    "    if type(atlas_map) == str or list:\n",
    "        dim = get_data(atlas_map).ndim\n",
    "        \n",
    "    else:\n",
    "        dim = atlas_map.ndim\n",
    "    \n",
    "    if dim == 4:\n",
    "        plotting.plot_prob_atlas(atlas_map, cut_coords = cut_coords, title = atlas, black_bg=True)\n",
    "        plt.savefig(f'./visualizations/atlas_maps/{atlas}.png')\n",
    "        plt.close()\n",
    "        \n",
    "    else:\n",
    "        plotting.plot_roi(atlas_map, cut_coords=cut_coords, title = atlas, black_bg = True)\n",
    "        plt.savefig(f'./visualizations/atlas_maps/{atlas}.png')\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4543fe93-cf16-4d9c-9e5e-997a9d8ec599",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/anandafrancis/opt/anaconda3/lib/python3.8/site-packages/nilearn/plotting/img_plotting.py:341: FutureWarning: Default resolution of the MNI template will change from 2mm to 1mm in version 0.10.0\n",
      "  anat_img = load_mni152_template()\n"
     ]
    }
   ],
   "source": [
    "# for each brain parcellation, generate the visual map\n",
    "for k in maps.keys():\n",
    "    plot_parcellation_map(k, maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a2154d-3ee1-42ee-a585-d2393e022c69",
   "metadata": {},
   "source": [
    "## **Geometric Projection Visuals**\n",
    "\n",
    "Visualize at linearly separability in 2D space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52e79524-c42c-4c20-8180-c4bf4af8f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D geometric projection\n",
    "X_pca_2D = PCA(n_components=2).fit_transform(X) \n",
    "X_tsne_2D = TSNE(n_components=2, learning_rate='auto', init='random', perplexity=3).fit_transform(X) \n",
    "X_isomap_2D = Isomap(n_components=2, n_neighbors=10).fit_transform(X) \n",
    "X_hessian_2D = LocallyLinearEmbedding(n_components=2, method='hessian', n_neighbors=262).fit_transform(X) #262\n",
    "X_mds_2D = MDS(n_components=2, dissimilarity='euclidean', normalized_stress='auto').fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "554c87dc-e1e3-4bdd-bbe3-ffb7b0fe02c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode your categorical labels into numerical values\n",
    "le_emotion = LabelEncoder()\n",
    "le_subject = LabelEncoder()\n",
    "le_priming = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical data\n",
    "emotion_encoded = le_emotion.fit_transform(emotion_class) \n",
    "subject_encoded = le_subject.fit_transform(subject_no)\n",
    "priming_encoded = le_priming.fit_transform(priming_class) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66a04b2c-686e-436c-b314-7fa280047410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dictionary for datasets of each dimension reduction method\n",
    "projection_2D = {'PCA': X_pca_2D, 'Isomap': X_isomap_2D, 'Hessian': X_hessian_2D, 'MDS': X_mds_2D, 't-SNE': X_tsne_2D}\n",
    "\n",
    "# save data as csv files to decrease loading time when kernel dies\n",
    "for key in projection_2D.keys():\n",
    "    data = projection_2D[key]\n",
    "    names = [f'Feat {i+1}' for i in range(len(data.T))]\n",
    "    df = pd.DataFrame(data, columns=names)\n",
    "    df['filename'] = files\n",
    "    df['subject'] = subject_no\n",
    "    df['emotion'] = emotion_class\n",
    "    df['priming'] = priming_class\n",
    "    projection_2D[key] = df\n",
    "    df.to_csv(f'./data/bivariate_data/{key}.csv', index=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7c301f82-1b66-433f-b7a9-6ae3225bbc39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embeddings(X_emb, y_encoded, title, target, filename, label_encoder):\n",
    "    '''\n",
    "    purpose: plot 2D embeddings with numerical labels\n",
    "    params:\n",
    "        X_emb: 2D array of embeddings\n",
    "        y_encoded: 1D array of numerical labels (e.g., output of LabelEncoder)\n",
    "        title: str, plot title\n",
    "        filename: str, optional, name to save the plot\n",
    "        label_encoder: sklearn.preprocessing.LabelEncoder, optional, to show original labels in colorbar\n",
    "    output: none, shows plot and saves to directory\n",
    "    '''\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    num_classes = len(np.unique(y_encoded))\n",
    "\n",
    "    feat_1 = X_emb.columns[0]\n",
    "    feat_2 = X_emb.columns[1]\n",
    "    X_emb = np.array(X_emb[[feat_1, feat_2]])\n",
    "    \n",
    "    base_cmap = colormaps.get_cmap('prism').resampled(num_classes)\n",
    "    custom_cmap = ListedColormap([base_cmap(i) for i in range(num_classes)])\n",
    "\n",
    "    scatter = plt.scatter(X_emb[:,0], X_emb[:,1], c=y_encoded, cmap=custom_cmap, alpha=0.6)\n",
    "    \n",
    "    cbar = plt.colorbar(scatter, ticks=np.unique(y_encoded), label='Class')\n",
    "    cbar.ax.set_yticklabels(label_encoder.inverse_transform(np.unique(y_encoded)))\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(feat_1)\n",
    "    plt.ylabel(feat_2)\n",
    "    plt.savefig(f'./visualizations/bivariate_data/{target}/{filename}')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1beb2f5a-70f0-4542-97f2-bc634c478b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot results\n",
    "for key in projection_2D.keys():\n",
    "    \n",
    "    plot_embeddings(projection_2D[key], subject_encoded, f\"{key} Visualization Separated by Subject No.\",\n",
    "                    'subject', f\"{key}_subject.png\", label_encoder=le_subject)\n",
    "\n",
    "    plot_embeddings(projection_2D[key], emotion_encoded, f\"{key} Visualization Separated by Emotion State.\",\n",
    "                    'emotion', f\"{key}_emotion.png\", label_encoder=le_emotion)\n",
    "\n",
    "    plot_embeddings(projection_2D[key], priming_encoded, f\"{key} Visualization Separated by Priming Condition.\",\n",
    "                    'priming', f\"{key}_priming.png\", label_encoder=le_priming)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78435854-0b20-4f2f-a8f9-166464aa7efa",
   "metadata": {},
   "source": [
    "## **Check for Multicollinearity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ab74f971-162d-4418-88d8-71a93de5bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrices\n",
    "def corr_matrix(dataset, data_dict):\n",
    "\n",
    "    # drop non-numeric or irrelevant columns\n",
    "    columns_to_exclude = ['filename', 'emotion', 'priming']\n",
    "    df = data_dict[dataset].drop(columns=columns_to_exclude, errors='ignore')\n",
    "    \n",
    "    # plot correlation heatmap\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    sns.heatmap(df.corr(), cmap='seismic', vmin=-1, vmax=1)\n",
    "    plt.title(f\"Correlation Heatmap for {dataset} Data\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./visualizations/collinearity/{dataset}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6f458d1-435f-4da6-bd70-3dd1f9ed288d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_matrix('Harvard_Oxford sub 0 x 1', parcellations)\n",
    "corr_matrix('Talairach Hemi x Lobe x Tissue', parcellations)\n",
    "corr_matrix('t-SNE', projections)\n",
    "corr_matrix('Hessian', projections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a582eecf-e49f-4c7f-af6c-dc5229c2a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_vif(X):\n",
    "    \n",
    "    # create VIF dataframe for covariates\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"feature\"] = X.columns\n",
    "    vif_data[\"VIF\"] = [vif(X.values, i) for i in range(len(X.columns))]\n",
    "    vif_data = vif_data.sort_values(by=['VIF'], ascending=False)\n",
    "    \n",
    "    return vif_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40689f4b-61b1-40a7-bd49-2c6e4f504e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_multico(df, name, num):\n",
    "    \"\"\"\n",
    "    purpose: removes multicollinear features from df based on VIF.\n",
    "\n",
    "    params:\n",
    "        df: pd.DataFrame: feature variables\n",
    "        num: int : number of features to remove.\n",
    "\n",
    "    output: percent: float: percentages of features that were removed for high VIF values\n",
    "    \"\"\"\n",
    "\n",
    "    # select only float64 and int64 columns\n",
    "    new_X = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "    \n",
    "\n",
    "    while True:\n",
    "\n",
    "        # calculate VIF and check if below threshold\n",
    "        vif_df = calc_vif(new_X)  \n",
    "        if vif_df[\"VIF\"].max() <= num:\n",
    "            break \n",
    "\n",
    "        # find feature with the highest VIF and drop it\n",
    "        feature_to_remove = vif_df.iloc[0][\"feature\"]\n",
    "        new_X = new_X.drop(columns=[feature_to_remove])\n",
    "        \n",
    "\n",
    "    # calculate % of features remove for collinearity\n",
    "    ratio = len(vif_df) / (len(df.columns) - 3)\n",
    "    percent = 100 - (ratio * 100)\n",
    "\n",
    "    # save vif dataframe\n",
    "    vif_df.to_csv(f'./data/collinearity/{name}_vif.csv', index=False)\n",
    "    \n",
    "    return percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3f67adcf-d555-49af-813e-d14b360d0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_multicollinearity(data, name, num):\n",
    "    '''\n",
    "    purpose: visualize percentages of multicollineratiry in feature extraction methods\n",
    "    params:\n",
    "        data: dict: key, value pairs of dataset names and pd.DataFrames\n",
    "        name: str: description of data subset\n",
    "    output: none, plots and saves bar chart of % of multicollinearity based on VIF > 5\n",
    "    '''\n",
    "\n",
    "    # store values\n",
    "    perc_multico = {}\n",
    "    \n",
    "    # for each dataset calculate % of the non-collinear features\n",
    "    for key in data.keys():\n",
    "        df = data[key]\n",
    "        perc = del_multico(df, key, num)\n",
    "        perc_multico[key] = perc\n",
    "\n",
    "        # visualize percentages of multicollineratiry in brain parcellation features\n",
    "        keys = list(perc_multico.keys())\n",
    "        vals = list(perc_multico.values())\n",
    "        \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(keys, vals, color='#c80909')\n",
    "    \n",
    "    plt.title('Percentage of Features Dropped to Make All VIF Values < 5')\n",
    "    plt.xlabel('Percent')\n",
    "    plt.ylabel('Parcellations')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'./visualizations/collinearity/{name}.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5d6ad85a-bc10-4448-ad05-0734bfc96fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify which methods produce the most multicollinearity \n",
    "plot_multicollinearity(parcellations, 'Brain Parcellations', 5)\n",
    "plot_multicollinearity(projections, 'Geometric Projections', 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e47fc51-e0b8-4278-b4e1-cc1b9e2eea00",
   "metadata": {},
   "source": [
    "## **Heterogeneity of Y Across X**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "df99c596-54c3-4d31-9940-2507d9d5347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_heterogeneity_of_var(data, name):\n",
    "\n",
    "    emo_p_values = {\n",
    "        'feature': [],\n",
    "        'p_value': [],\n",
    "        'method': []\n",
    "    }\n",
    "    pri_p_values = {\n",
    "        'feature': [],\n",
    "        'p_value': [],\n",
    "        'method': []\n",
    "    }\n",
    "    \n",
    "    for method in data.keys():\n",
    "\n",
    "        # select only on input column\n",
    "        df = data[method]\n",
    "\n",
    "        for input_col in df.columns:\n",
    "            if (input_col == 'emotion') or (input_col == 'priming') or (input_col == 'subject') or (input_col == 'filename'):\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                \n",
    "                # get p values for each class comparison\n",
    "                anger = df[df['emotion'] == 'anger'][input_col]\n",
    "                disgust = df[df['emotion'] == 'disgust'][input_col]\n",
    "                fear = df[df['emotion'] == 'fear'][input_col]\n",
    "        \n",
    "                con = df[df['priming'] == 'congruent'][input_col]\n",
    "                incon = df[df['priming'] == 'incongruent'][input_col]\n",
    "                neu = df[df['priming'] == 'neutral'][input_col]\n",
    "        \n",
    "                emo_stat, emo_p = stats.levene(anger, disgust, fear)\n",
    "                pri_stat, pri_p = stats.levene(con, incon, neu)\n",
    "        \n",
    "                emo_p_values['p_value'].append(emo_p)\n",
    "                emo_p_values['feature'].append(input_col)\n",
    "                emo_p_values['method'].append(method)\n",
    "\n",
    "                pri_p_values['p_value'].append(pri_p)\n",
    "                pri_p_values['feature'].append(input_col)\n",
    "                pri_p_values['method'].append(method)\n",
    "\n",
    "\n",
    "                if emo_p <= 0.05:\n",
    "                \n",
    "                    # create a new figure and axes for each plot\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    \n",
    "                    # create the violin plot\n",
    "                    sns.violinplot(data=df, x=\"emotion\", y=input_col, hue=\"priming\", fill=False, palette='prism')\n",
    "                    \n",
    "                    # add the title and labels\n",
    "                    plt.title(f'Heterogeneity of Variance of {method} for {input_col} Over Emotion Classes')\n",
    "                    plt.xlabel('Emotion Class')\n",
    "                    plt.ylabel(f'{method} {input_col}')\n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    # save visual to directory\n",
    "                    plt.savefig(f'./visualizations/heteroscedasticity/{method}_{input_col}_emo.png')\n",
    "                    plt.close()\n",
    "\n",
    "                if pri_p <= 0.05:\n",
    "                \n",
    "                    # create a new figure and axes for each plot\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    \n",
    "                    # create the violin plot\n",
    "                    sns.violinplot(data=df, x=\"priming\", y=input_col, hue=\"emotion\", fill=False, palette='prism')\n",
    "                    \n",
    "                    # add the title and labels\n",
    "                    plt.title(f'Heterogeneity of Variance of {method} for {input_col} Over Priming Classes')\n",
    "                    plt.xlabel('Emotion Class')\n",
    "                    plt.ylabel(f'{method} {input_col}')\n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    # save visual to directory\n",
    "                    plt.savefig(f'./visualizations/heteroscedasticity/{method}_{input_col}_pri.png')\n",
    "                    plt.close()\n",
    "\n",
    "\n",
    "    \n",
    "    # get p values for all methods\n",
    "    emo_p_df = pd.DataFrame(emo_p_values)\n",
    "    pri_p_df = pd.DataFrame(pri_p_values)\n",
    "\n",
    "    emo_p_df.to_csv(f'./data/heteroscedasticity/{name}_feat_levene_emo.csv', index=False)\n",
    "    pri_p_df.to_csv(f'./data/heteroscedasticity/{name}_feat_levene_pri.csv', index=False)\n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    # calculate percentage of p-values ≤ 0.05 for each method\n",
    "    emo_sig_pct = emo_p_df.groupby('method').apply(lambda df: (df['p_value'] <= 0.05).mean() * 100)\n",
    "    pri_sig_pct = pri_p_df.groupby('method').apply(lambda df: (df['p_value'] <= 0.05).mean() * 100)\n",
    "\n",
    "\n",
    "    \n",
    "    # plot % of significant p-values for emotion class\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(emo_sig_pct.index, emo_sig_pct.values, color='#c80909')\n",
    "    plt.title(f'Percent of Significant Levene Test P-values for Emotion Classes ({name})')\n",
    "    plt.xlabel('% of p-values ≤ 0.05')\n",
    "    plt.ylabel(f'{name} Methods')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'./visualizations/heteroscedasticity/{name}_emo_levene.png')\n",
    "    plt.close()\n",
    "    \n",
    "    # plot % of significant p-values for priming class\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.barh(pri_sig_pct.index, pri_sig_pct.values, color='#c80909')\n",
    "    plt.title(f'Percent of Significant Levene Test P-values for Priming Classes ({name})')\n",
    "    plt.xlabel('% of p-values ≤ 0.05')\n",
    "    plt.ylabel(f'{name} Methods')\n",
    "    plt.tight_layout()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(f'./visualizations/heteroscedasticity/{name}_pri_levene.png')\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "056416c7-7b10-40ae-9cb8-a0c2c48cdd50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# identify which methods produce the most heteroscedasticity \n",
    "plot_heterogeneity_of_var(parcellations, 'Brain Parcellations')\n",
    "plot_heterogeneity_of_var(projections, 'Geometric Projections')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed924c71-3e6b-4971-bd3a-ac2103a2f1d0",
   "metadata": {},
   "source": [
    "## **Auto-Correlation Across Features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe77b496-132f-4a13-8184-76b6e566aa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_autocorrelation(method_dfs):\n",
    "\n",
    "    # store correlations\n",
    "    average_correlations = {}\n",
    "    feature_correlations = {}\n",
    "    \n",
    "    for method, df in method_dfs.items():\n",
    "        \n",
    "        # ensure no modification of original data and only assess input features\n",
    "        new_df = df.select_dtypes(include=['float64', 'int64']).copy()\n",
    "    \n",
    "        # correlate each feature with subject number\n",
    "        feature_corrs = new_df.drop(columns='subject').corrwith(df['subject'])\n",
    "        \n",
    "        # Store detailed correlation DataFrame\n",
    "        feature_correlations[method] = pd.DataFrame({\n",
    "            'feature': feature_corrs.index,\n",
    "            'corrcoef': feature_corrs.values\n",
    "        })\n",
    "    \n",
    "        feature_correlations[method].to_csv(f'./data/autocorrelation/{method}.csv', index=False)\n",
    "    \n",
    "        # average absolute correlation\n",
    "        average_correlations[method] = feature_correlations[method]['corrcoef'].abs().mean()\n",
    "    \n",
    "    # create DataFrame for plotting\n",
    "    correlation_df = pd.DataFrame.from_dict(average_correlations, orient='index', columns=['Avg_Correlation'])\n",
    "    correlation_df = correlation_df.sort_values('Avg_Correlation', ascending=False).reset_index()\n",
    "    correlation_df.columns = ['Method', 'Avg_Correlation']\n",
    "    \n",
    "    # create and store visualization\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=correlation_df, x='Method', y='Avg_Correlation', palette='hsv')\n",
    "    plt.title('Average Feature Autocorrelation with Subject Number by Method')\n",
    "    plt.ylabel('Average Absolute Correlation')\n",
    "    plt.xlabel('Feature Extraction Method')\n",
    "    plt.xticks(rotation=85)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'./visualizations/autocorrelation/average_corrcoef_subject.png')\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ffddb474-b20c-4cd2-8924-d22e54361c24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gd/vj6nrxx1037dp6b1bqg_hg3c0000gn/T/ipykernel_75312/2729043456.py:34: FutureWarning: \n",
      "\n",
      "Passing `palette` without assigning `hue` is deprecated and will be removed in v0.14.0. Assign the `x` variable to `hue` and set `legend=False` for the same effect.\n",
      "\n",
      "  sns.barplot(data=correlation_df, x='Method', y='Avg_Correlation', palette='hsv')\n"
     ]
    }
   ],
   "source": [
    "extracted_features = {**parcellations, **projections}\n",
    "measure_autocorrelation(extracted_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990b72cf-6b6a-406c-aaaf-9d481ba3e97f",
   "metadata": {},
   "source": [
    "# **Model Development**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9266e11-a588-41f2-ab30-6a603b465118",
   "metadata": {},
   "source": [
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "        \n",
    "    def logistic_regression(X, y, lr=0.5, epochs=100):\n",
    "        \n",
    "        # intialize \n",
    "        n_instances, m_feats = X.shape\n",
    "        w = np.zeros(m_feats)\n",
    "    \n",
    "        for e in range(epochs): \n",
    "    \n",
    "            # calculate logit of weighted sum\n",
    "            y_pred = sigmoid(np.dot(X, w))\n",
    "        \n",
    "            # calculate errors (gradient)\n",
    "            residuals = y_pred - y\n",
    "        \n",
    "            # update weights\n",
    "            w -= (lr / n_instances) * np.dot(X.T, residuals)\n",
    "    \n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a4976880-d2f1-428b-9c67-d95fbb9659a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove redundancy\n",
    "del extracted_features['Talairach Hemi']\n",
    "del extracted_features['Talairach Tissue']\n",
    "del extracted_features['Talairach Lobe']\n",
    "\n",
    "feat_ex_methods = extracted_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2af018de-76d0-4ca4-af57-271e7523162c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HierarchicalKFoldCV:\n",
    "\n",
    "    def __init__(self, method, model, data_dict, hier_class, target_class, n_splits=5):\n",
    "        self.data = data_dict[method]\n",
    "        self.method = method\n",
    "        self.hier_class = hier_class\n",
    "        self.target_class = target_class\n",
    "        self.n_splits = n_splits\n",
    "        self.model_name = model\n",
    "\n",
    "        if model == 'log_reg':\n",
    "            self.model = LogisticRegression(penalty='l2', dual=False, multi_class='multinomial',\n",
    "                                        warm_start=True, max_iter=5000)\n",
    "\n",
    "        # For storing across folds\n",
    "        self.all_coefs = []\n",
    "        self.misclassified_records = []\n",
    "\n",
    "        # intialize output directories\n",
    "        base_path = f\"./data/{model}_results\"\n",
    "        self.output_paths = {\n",
    "            'confusions': f\"{base_path}/confusion_matrices\",\n",
    "            'coefficients': f\"{base_path}/coefficients\",\n",
    "            'classification_reports': f\"{base_path}/classification_reports\",\n",
    "            'errors': f\"{base_path}/errors\",\n",
    "            'metrics': f\"{base_path}/metrics\",\n",
    "        }\n",
    "\n",
    "    def _separate_input_target(self):\n",
    "        X = self.data.select_dtypes(include=['float64', 'int64']).drop(columns=[self.target_class], errors='ignore')\n",
    "        y = self.data[self.target_class]\n",
    "        groups = self.data[self.hier_class]\n",
    "        \n",
    "        return X, y, groups\n",
    "\n",
    "    def _save_model_weights(self, feature_names):\n",
    "        avg_coef = np.mean(self.all_coefs, axis=0)\n",
    "        classes = self.model.classes_\n",
    "\n",
    "        if avg_coef.ndim == 1:\n",
    "            avg_coef = avg_coef.reshape(1, -1)\n",
    "\n",
    "        weights_df = pd.DataFrame(avg_coef, columns=feature_names)\n",
    "        weights_df['class'] = classes\n",
    "        weights_df = weights_df.set_index('class').transpose()\n",
    "        weights_df.to_csv(f\"{self.output_paths['coefficients']}/{self.method}_{self.target_class}.csv\")\n",
    "\n",
    "    def _compute_and_save_metrics(self, y_true, y_pred, dataset_type):\n",
    "\n",
    "        try:\n",
    "            proba = self.model.predict_proba(self.X_test if dataset_type == 'test' else self.X_train)\n",
    "            roc_auc = roc_auc_score(y_true, proba, average='micro', multi_class='ovr')\n",
    "        except:\n",
    "            roc_auc = 0\n",
    "\n",
    "        report = classification_report(y_true, y_pred, output_dict=True, zero_division=np.nan)\n",
    "        report_df = pd.DataFrame(report).transpose()\n",
    "        report_df.to_csv(f\"{self.output_paths['classification_reports']}/{self.method}_{self.target_class}_{dataset_type}.csv\")\n",
    "\n",
    "        return roc_auc\n",
    "\n",
    "    def _save_confusion_matrix(self, y_true, y_pred, dataset_type):\n",
    "\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        \n",
    "        labels = unique_labels(y_true, y_pred)\n",
    "        cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
    "       \n",
    "        plt.title(f\"{dataset_type.capitalize()} Confusion Matrix\")\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f\"{self.output_paths['confusions']}/{self.method}_{self.target_class}_{dataset_type}.png\")\n",
    "        plt.close()\n",
    "\n",
    "    def _accumulate_misclassifications(self, X, y_true, y_pred):\n",
    "        misclassified_mask = y_true != y_pred\n",
    "        misclassified_indices = X.index[misclassified_mask]\n",
    "    \n",
    "        # full original rows\n",
    "        misclassified = self.data.loc[misclassified_indices]\n",
    "    \n",
    "        # ensure Series alignment\n",
    "        true_labels = y_true.loc[misclassified_indices].reset_index(drop=True)\n",
    "        pred_labels = pd.Series(y_pred).iloc[misclassified_mask.values].reset_index(drop=True)\n",
    "    \n",
    "        misclassified_df = pd.concat([\n",
    "            misclassified.reset_index(drop=True),\n",
    "            true_labels.rename(\"true_label\"),\n",
    "            pred_labels.rename(\"predicted_label\")\n",
    "        ], axis=1)\n",
    "    \n",
    "        self.misclassified_records.append(misclassified_df)\n",
    "\n",
    "\n",
    "\n",
    "    def _save_aggregated_misclassifications(self):\n",
    "        if not self.misclassified_records:\n",
    "            return\n",
    "        all_misclassified = pd.concat(self.misclassified_records, ignore_index=True)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\", category=PerformanceWarning)\n",
    "            deduped = all_misclassified.groupby(all_misclassified.columns.tolist()).size().reset_index(name='error_count')\n",
    "        deduped.to_csv(f\"{self.output_paths['errors']}/{self.method}_{self.target_class}.csv\", index=False)\n",
    "\n",
    "    \n",
    "    def evaluate(self):\n",
    "        X, y, groups = self._separate_input_target()\n",
    "        gkf = GroupKFold(n_splits=self.n_splits)\n",
    "\n",
    "        train_roc_auc = 0\n",
    "        test_roc_auc = 0\n",
    "\n",
    "        for fold, (train_idx, test_idx) in enumerate(gkf.split(X, y, groups=groups), start=1):\n",
    "            self.X_train, self.X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "            y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "            # save most recent model configuration\n",
    "            self.model.fit(self.X_train, y_train)\n",
    "            joblib.dump(self.model, f'./data/models/{self.model_name}_fold_{fold}_target_class.pkl')\n",
    "            self.all_coefs.append(self.model.coef_)\n",
    "\n",
    "            y_pred_train = self.model.predict(self.X_train)\n",
    "            y_pred_test = self.model.predict(self.X_test)\n",
    "\n",
    "            train_roc_auc += self._compute_and_save_metrics(y_train, y_pred_train, \"train\")\n",
    "            test_roc_auc += self._compute_and_save_metrics(y_test, y_pred_test, \"test\")\n",
    "\n",
    "\n",
    "            self._save_confusion_matrix(y_train, y_pred_train, \"train\")\n",
    "            self._save_confusion_matrix(y_test, y_pred_test, \"test\")\n",
    "\n",
    "            self._accumulate_misclassifications(self.X_test.copy(), y_test, y_pred_test)\n",
    "\n",
    "        # save averaged results\n",
    "        self._save_model_weights(feature_names=self.X_train.columns)\n",
    "        self._save_aggregated_misclassifications()\n",
    "\n",
    "        \n",
    "\n",
    "        return train_roc_auc/self.n_splits , test_roc_auc/self.n_splits , self.method, self.target_class, self.X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47979cb2-b0fc-4a98-8d53-a07bcfd8d668",
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_dict = {'roc_train_emo': [], 'roc_test_emo': [], 'method': [], \n",
    "                'roc_train_pri': [], 'roc_test_pri': [], 'feature_count' : []}\n",
    "\n",
    "for app in feat_ex_methods:\n",
    "    \n",
    "    # run model on all extracted feature methods\n",
    "    tr_e, te_e, me_e, ta_e, fe_e = HierarchicalKFoldCV(method=app, data_dict=extracted_features, hier_class='subject', \n",
    "                                         target_class='emotion', n_splits=2, model='log_reg').evaluate()\n",
    "    tr_p, te_p, me_p, ta_p, fe_p = HierarchicalKFoldCV(method=app, data_dict=extracted_features, hier_class='subject', \n",
    "                                         target_class='priming', n_splits=2, model='log_reg').evaluate()\n",
    "\n",
    "    # store metric values for all extracted feature methods\n",
    "    roc_auc_dict['roc_train_emo'].append(tr_e)\n",
    "    roc_auc_dict['roc_test_emo'].append(te_e)\n",
    "    roc_auc_dict['method'].append(app)\n",
    "    roc_auc_dict['feature_count'].append(fe_e)\n",
    "    roc_auc_dict['roc_train_pri'].append(tr_p)\n",
    "    roc_auc_dict['roc_test_pri'].append(te_p)\n",
    "\n",
    "pd.DataFrame(roc_auc_dict).to_csv('./data/log_reg_results/metrics/roc_auc.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c947fb6-808e-46d9-91c3-c5447705f639",
   "metadata": {},
   "source": [
    "# **Interpretation & Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25bd0c2-892e-421d-a908-318ed43f6687",
   "metadata": {},
   "source": [
    "## **Multicollinearity Results**\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/collinearity/Brain Parcellations.png\" alt=\"image\" width=\"800\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/collinearity/Geometric Projections.png\" alt=\"image\" width=\"800\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/collinearity/Harvard_Oxford sub 0 x 1.png\" alt=\"image\" width=\"800\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/collinearity/Talairach Hemi x Lobe x Tissue.png\" alt=\"image\" width=\"800\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/collinearity/Hessian.png\" alt=\"image\" width=\"500\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/collinearity/t-SNE.png\" alt=\"image\" width=\"500\" />\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7b03a0c4-d669-4ce3-88db-961180f5d4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# store complete VIF dataframes\n",
    "\n",
    "# aggregate them all to one dataframe\n",
    "\n",
    "# sort values and save csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb93e1a-f6a6-416e-a248-1e4aa54921fd",
   "metadata": {},
   "source": [
    "## **Homogeneity of Variance Results**\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/heteroscedasticity/Brain Parcellations_emo_levene.png\" alt=\"image\" width=\"800\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/heteroscedasticity/Brain Parcellations_pri_levene.png\" alt=\"image\" width=\"800\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/heteroscedasticity/Geometric Projections_emo_levene.png\" alt=\"image\" width=\"800\" />\n",
    "</div>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/heteroscedasticity/Geometric Projections_pri_levene.png\" alt=\"image\" width=\"800\" />\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ae7ec34c-afe4-4bc4-8156-51126b0ee673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the levene p values to one dataframe\n",
    "\n",
    "# sort values and save csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb7b21e-9ac8-47d0-a25a-e9d4b19e7029",
   "metadata": {},
   "source": [
    "## **Auto-correlation Results**\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"./visualizations/autocorrelation/average_corrcoef_subject.png\" alt=\"image\" width=\"1000\" />\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "79521e5a-3333-42a8-a694-72d0ed9421a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the correlation coefficients of input features to subject number to one dataframe\n",
    "\n",
    "# sort values and save csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48275d99-572b-48ab-9ecd-434c2e153df5",
   "metadata": {},
   "source": [
    "## **Logistic Regression Results**\n",
    "\n",
    "### \n",
    "\n",
    "**<h2 style=\"text-align: center;\">TOP 5 EMOTION COEFFICIENTS BY FEATURE</h2>**\n",
    "\n",
    "|    | feature                                                    | method                     | label         |      coef |\n",
    "|---:|:-----------------------------------------------------------|:---------------------------|:--------------|----------:|\n",
    "|  0 | Brodmann area 11                                           | Talairach Ba               | anger_coefs   |  0.997122 |\n",
    "|  1 | Left Lingual Gyrus                                         | Harvard_Oxford cortl 0 x 1 | anger_coefs   |  0.75641  |\n",
    "|  2 | Middle Frontal Gyrus                                       | Talairach Gyrus            | anger_coefs   | -0.725181 |\n",
    "|  3 | b'7Networks_LH_Vis_8'                                      | Schaefer 100 x 7 x 1       | anger_coefs   | -0.723426 |\n",
    "|  4 | Left Occipital Fusiform Gyrus                              | Harvard_Oxford cortl 0 x 1 | anger_coefs   | -0.71395  |\n",
    "|  5 | Right Central Opercular Cortex                             | Harvard_Oxford cortl 0 x 1 | fear_coefs    | -0.862423 |\n",
    "|  6 | Brodmann area 11                                           | Talairach Ba               | fear_coefs    | -0.783936 |\n",
    "|  7 | Pulvinar                                                   | Talairach Ba               | fear_coefs    | -0.700187 |\n",
    "|  8 | Calcarine_L                                                | AAL SPM12                  | fear_coefs    |  0.688515 |\n",
    "|  9 | Brodmann area 43                                           | Talairach Ba               | fear_coefs    | -0.664949 |\n",
    "| 10 | GM Visual cortex V2 BA18                                   | Juelich 0 x 1              | disgust_coefs |  0.713902 |\n",
    "| 11 | GM Secondary somatosensory cortex / Parietal operculum OP2 | Juelich 0 x 1              | disgust_coefs | -0.696101 |\n",
    "| 12 | Right Central Opercular Cortex                             | Harvard_Oxford cortl 0 x 1 | disgust_coefs |  0.690772 |\n",
    "| 13 | Vermis_9                                                   | AAL SPM12                  | disgust_coefs | -0.613373 |\n",
    "| 14 | Caudate_R                                                  | AAL SPM12                  | disgust_coefs | -0.605213 |\n",
    "\n",
    "<br/>\n",
    "\n",
    "**<h2 style=\"text-align: center;\">TOP 5 PRIMING COEFFICIENTS BY FEATURE</h2>**\n",
    "\n",
    "|    | feature                                      | method                         | label             |      coef |\n",
    "|---:|:---------------------------------------------|:-------------------------------|:------------------|----------:|\n",
    "|  0 | Middle Temporal Gyrus                        | Talairach Gyrus                | neutral_coefs     |  1.7935   |\n",
    "|  1 | Middle Temporal Gyrus, temporooccipital part | Harvard_Oxford cort 0 x 1      | neutral_coefs     |  1.3369   |\n",
    "|  2 | Brodmann area 39                             | Talairach Ba                   | neutral_coefs     |  1.20373  |\n",
    "|  3 | Temporal Lobe                                | Talairach Hemi x Lobe x Tissue | neutral_coefs     |  1.19578  |\n",
    "|  4 | GM Inferior parietal lobule PGp              | Juelich 0 x 1                  | neutral_coefs     |  1.10605  |\n",
    "|  5 | Middle Temporal Gyrus                        | Talairach Gyrus                | congruent_coefs   | -1.04918  |\n",
    "|  6 | Feat 7                                       | Hessian                        | congruent_coefs   |  0.858455 |\n",
    "|  7 | Posterior Cingulate                          | Talairach Gyrus                | congruent_coefs   | -0.818125 |\n",
    "|  8 | Feat 4                                       | Hessian                        | congruent_coefs   | -0.806589 |\n",
    "|  9 | GM Broca's area BA44                         | Juelich 0 x 1                  | congruent_coefs   | -0.79721  |\n",
    "| 10 | Temporal Lobe                                | Talairach Hemi x Lobe x Tissue | incongruent_coefs | -1.1329   |\n",
    "| 11 | Lateral Occipital Cortex, inferior division  | Harvard_Oxford cort 0 x 1      | incongruent_coefs | -1.07     |\n",
    "| 12 | GM Inferior parietal lobule Pga              | Juelich 0 x 1                  | incongruent_coefs | -0.983688 |\n",
    "| 13 | Lingual Gyrus                                | Talairach Gyrus                | incongruent_coefs |  0.967608 |\n",
    "| 14 | Limbic Lobe                                  | Talairach Hemi x Lobe x Tissue | incongruent_coefs |  0.948026 |\n",
    "\n",
    "\n",
    "<br/>\n",
    "\n",
    "**<h2 style=\"text-align: center;\">ROC AUC SCORES BY METHOD</h2>**\n",
    "\n",
    "|    |   roc_train_emo |   roc_test_emo | method                         |   roc_train_pri |   roc_test_pri |   feature_count |   emo_overfit |   pri_overfit |\n",
    "|---:|----------------:|---------------:|:-------------------------------|----------------:|---------------:|----------------:|--------------:|--------------:|\n",
    "|  0 |        0.855926 |       0.560631 | Harvard_Oxford cort 0 x 1      |        0.992428 |       0.813374 |              49 |      0.654999 |      0.81958  |\n",
    "|  1 |        0.986241 |       0.54406  | Harvard_Oxford cortl 0 x 1     |        1        |       0.782291 |              97 |      0.55165  |      0.782291 |\n",
    "|  2 |        0.708313 |       0.520329 | Harvard_Oxford sub 0 x 1       |        0.777956 |       0.623964 |              22 |      0.734604 |      0.802056 |\n",
    "|  3 |        0.886845 |       0.573813 | Juelich 0 x 1                  |        0.997613 |       0.806996 |              63 |      0.647028 |      0.808927 |\n",
    "|  4 |        0.99893  |       0.528944 | AAL SPM12                      |        1        |       0.779451 |             117 |      0.52951  |      0.779451 |\n",
    "|  5 |        0.887435 |       0.511838 | Talairach Gyrus                |        0.996543 |       0.808189 |              56 |      0.576761 |      0.810993 |\n",
    "|  6 |        0.940521 |       0.536461 | Talairach Ba                   |        0.999767 |       0.773416 |              72 |      0.570387 |      0.773596 |\n",
    "|  7 |        0.999246 |       0.539355 | Schaefer 100 x 7 x 1           |        1        |       0.853937 |             101 |      0.539763 |      0.853937 |\n",
    "|  8 |        0.697915 |       0.506626 | Talairach Hemi x Lobe x Tissue |        0.859081 |       0.698985 |              23 |      0.725913 |      0.813643 |\n",
    "|  9 |        1        |       0.531509 | PCA                            |        1        |       0.855309 |             227 |      0.531509 |      0.855309 |\n",
    "| 10 |        0.864842 |       0.480521 | Isomap                         |        1        |       0.670309 |              52 |      0.555617 |      0.670309 |\n",
    "| 11 |        0.625144 |       0.497558 | Hessian                        |        0.860809 |       0.798477 |              22 |      0.79591  |      0.927589 |\n",
    "| 12 |        0.578765 |       0.488532 | MDS                            |        0.697298 |       0.61904  |               6 |      0.844094 |      0.88777  |\n",
    "| 13 |        0.529575 |       0.47904  | t-SNE                          |        0.532044 |       0.506447 |               4 |      0.904574 |      0.95189  |\n",
    "\n",
    "<br />\n",
    "\n",
    "**<h2 style=\"text-align: center;\">F1 SCORES BY METHOD</h2>**\n",
    "\n",
    "|    | method                         | label       |       f1 |\n",
    "|---:|:-------------------------------|:------------|---------:|\n",
    "|  0 | PCA                            | congruent   | 0.715789 |\n",
    "|  1 | Talairach Gyrus                | congruent   | 0.649123 |\n",
    "|  2 | Schaefer 100 x 7 x 1           | congruent   | 0.627451 |\n",
    "|  3 | Harvard_Oxford cort 0 x 1      | congruent   | 0.616667 |\n",
    "|  4 | Juelich 0 x 1                  | congruent   | 0.597938 |\n",
    "|  5 | Schaefer 100 x 7 x 1           | incongruent | 0.688889 |\n",
    "|  6 | PCA                            | incongruent | 0.678899 |\n",
    "|  7 | Juelich 0 x 1                  | incongruent | 0.659091 |\n",
    "|  8 | Harvard_Oxford cortl 0 x 1     | incongruent | 0.629213 |\n",
    "|  9 | Talairach Hemi x Lobe x Tissue | incongruent | 0.607143 |\n",
    "| 10 | Schaefer 100 x 7 x 1           | neutral     | 0.769231 |\n",
    "| 11 | Talairach Gyrus                | neutral     | 0.736842 |\n",
    "| 12 | Juelich 0 x 1                  | neutral     | 0.705882 |\n",
    "| 13 | Harvard_Oxford cort 0 x 1      | neutral     | 0.693333 |\n",
    "| 14 | Hessian                        | neutral     | 0.666667 |\n",
    "| 15 | Talairach Ba                   | anger       | 0.48     |\n",
    "| 16 | Juelich 0 x 1                  | anger       | 0.463158 |\n",
    "| 17 | AAL SPM12                      | anger       | 0.453782 |\n",
    "| 18 | MDS                            | anger       | 0.412698 |\n",
    "| 19 | PCA                            | anger       | 0.396226 |\n",
    "| 20 | Harvard_Oxford sub 0 x 1       | disgust     | 0.361702 |\n",
    "| 21 | Schaefer 100 x 7 x 1           | disgust     | 0.337079 |\n",
    "| 22 | Talairach Hemi x Lobe x Tissue | disgust     | 0.318841 |\n",
    "| 23 | Juelich 0 x 1                  | disgust     | 0.315789 |\n",
    "| 24 | t-SNE                          | disgust     | 0.307692 |\n",
    "| 25 | Juelich 0 x 1                  | fear        | 0.505051 |\n",
    "| 26 | Talairach Hemi x Lobe x Tissue | fear        | 0.432    |\n",
    "| 27 | PCA                            | fear        | 0.426966 |\n",
    "| 28 | Harvard_Oxford cortl 0 x 1     | fear        | 0.422222 |\n",
    "| 29 | Harvard_Oxford sub 0 x 1       | fear        | 0.404762 |\n",
    "\n",
    "<br />\n",
    "\n",
    "**<h2 style=\"text-align: center;\">CHI-SQUARE ASSOCIATION FOR RESIDUALS</h2>**\n",
    "\n",
    "|     | method                         | target   | feat_1          | feat_2          |     p_value |\n",
    "|----:|:-------------------------------|:---------|:----------------|:----------------|------------:|\n",
    "|   2 | Harvard_Oxford cort 0 x 1      | emotion  | subject         | predicted_label | 3.8911e-09  |\n",
    "|   5 | Harvard_Oxford cort 0 x 1      | emotion  | emotion         | predicted_label | 2.07755e-17 |\n",
    "|   9 | Harvard_Oxford cort 0 x 1      | emotion  | predicted_label | subject         | 3.8911e-09  |\n",
    "|  10 | Harvard_Oxford cort 0 x 1      | emotion  | predicted_label | emotion         | 2.07755e-17 |\n",
    "|  13 | Harvard_Oxford cort 0 x 1      | priming  | subject         | priming         | 0.0498261   |\n",
    "|  14 | Harvard_Oxford cort 0 x 1      | priming  | subject         | predicted_label | 4.37921e-12 |\n",
    "|  18 | Harvard_Oxford cort 0 x 1      | priming  | priming         | subject         | 0.0498261   |\n",
    "|  20 | Harvard_Oxford cort 0 x 1      | priming  | priming         | predicted_label | 1.43065e-10 |\n",
    "|  21 | Harvard_Oxford cort 0 x 1      | priming  | predicted_label | subject         | 4.37921e-12 |\n",
    "|  23 | Harvard_Oxford cort 0 x 1      | priming  | predicted_label | priming         | 1.43065e-10 |\n",
    "|  26 | Harvard_Oxford cortl 0 x 1     | emotion  | subject         | predicted_label | 8.45044e-12 |\n",
    "|  29 | Harvard_Oxford cortl 0 x 1     | emotion  | emotion         | predicted_label | 2.9766e-18  |\n",
    "|  33 | Harvard_Oxford cortl 0 x 1     | emotion  | predicted_label | subject         | 8.45044e-12 |\n",
    "|  34 | Harvard_Oxford cortl 0 x 1     | emotion  | predicted_label | emotion         | 2.9766e-18  |\n",
    "|  37 | Harvard_Oxford cortl 0 x 1     | priming  | subject         | priming         | 0.00683838  |\n",
    "|  38 | Harvard_Oxford cortl 0 x 1     | priming  | subject         | predicted_label | 1.21349e-08 |\n",
    "|  42 | Harvard_Oxford cortl 0 x 1     | priming  | priming         | subject         | 0.00683838  |\n",
    "|  44 | Harvard_Oxford cortl 0 x 1     | priming  | priming         | predicted_label | 1.83898e-12 |\n",
    "|  45 | Harvard_Oxford cortl 0 x 1     | priming  | predicted_label | subject         | 1.21349e-08 |\n",
    "|  47 | Harvard_Oxford cortl 0 x 1     | priming  | predicted_label | priming         | 1.83898e-12 |\n",
    "|  50 | Harvard_Oxford sub 0 x 1       | emotion  | subject         | predicted_label | 1.09737e-06 |\n",
    "|  53 | Harvard_Oxford sub 0 x 1       | emotion  | emotion         | predicted_label | 5.6732e-18  |\n",
    "|  57 | Harvard_Oxford sub 0 x 1       | emotion  | predicted_label | subject         | 1.09737e-06 |\n",
    "|  58 | Harvard_Oxford sub 0 x 1       | emotion  | predicted_label | emotion         | 5.6732e-18  |\n",
    "|  62 | Harvard_Oxford sub 0 x 1       | priming  | subject         | predicted_label | 1.22515e-06 |\n",
    "|  68 | Harvard_Oxford sub 0 x 1       | priming  | priming         | predicted_label | 4.61949e-15 |\n",
    "|  69 | Harvard_Oxford sub 0 x 1       | priming  | predicted_label | subject         | 1.22515e-06 |\n",
    "|  71 | Harvard_Oxford sub 0 x 1       | priming  | predicted_label | priming         | 4.61949e-15 |\n",
    "|  74 | Juelich 0 x 1                  | emotion  | subject         | predicted_label | 2.35824e-11 |\n",
    "|  77 | Juelich 0 x 1                  | emotion  | emotion         | predicted_label | 7.82954e-17 |\n",
    "|  81 | Juelich 0 x 1                  | emotion  | predicted_label | subject         | 2.35824e-11 |\n",
    "|  82 | Juelich 0 x 1                  | emotion  | predicted_label | emotion         | 7.82954e-17 |\n",
    "|  86 | Juelich 0 x 1                  | priming  | subject         | predicted_label | 4.95935e-06 |\n",
    "|  92 | Juelich 0 x 1                  | priming  | priming         | predicted_label | 7.45783e-12 |\n",
    "|  93 | Juelich 0 x 1                  | priming  | predicted_label | subject         | 4.95935e-06 |\n",
    "|  95 | Juelich 0 x 1                  | priming  | predicted_label | priming         | 7.45783e-12 |\n",
    "|  98 | AAL SPM12                      | emotion  | subject         | predicted_label | 6.64931e-16 |\n",
    "| 101 | AAL SPM12                      | emotion  | emotion         | predicted_label | 1.02118e-17 |\n",
    "| 105 | AAL SPM12                      | emotion  | predicted_label | subject         | 6.64931e-16 |\n",
    "| 106 | AAL SPM12                      | emotion  | predicted_label | emotion         | 1.02118e-17 |\n",
    "| 109 | AAL SPM12                      | priming  | subject         | priming         | 0.012332    |\n",
    "| 110 | AAL SPM12                      | priming  | subject         | predicted_label | 1.09439e-10 |\n",
    "| 114 | AAL SPM12                      | priming  | priming         | subject         | 0.012332    |\n",
    "| 116 | AAL SPM12                      | priming  | priming         | predicted_label | 9.39201e-13 |\n",
    "| 117 | AAL SPM12                      | priming  | predicted_label | subject         | 1.09439e-10 |\n",
    "| 119 | AAL SPM12                      | priming  | predicted_label | priming         | 9.39201e-13 |\n",
    "| 122 | Talairach Gyrus                | emotion  | subject         | predicted_label | 5.82423e-08 |\n",
    "| 125 | Talairach Gyrus                | emotion  | emotion         | predicted_label | 5.13539e-19 |\n",
    "| 129 | Talairach Gyrus                | emotion  | predicted_label | subject         | 5.82423e-08 |\n",
    "| 130 | Talairach Gyrus                | emotion  | predicted_label | emotion         | 5.13539e-19 |\n",
    "| 133 | Talairach Gyrus                | priming  | subject         | priming         | 0.00201984  |\n",
    "| 134 | Talairach Gyrus                | priming  | subject         | predicted_label | 2.1688e-08  |\n",
    "| 138 | Talairach Gyrus                | priming  | priming         | subject         | 0.00201984  |\n",
    "| 140 | Talairach Gyrus                | priming  | priming         | predicted_label | 8.33995e-11 |\n",
    "| 141 | Talairach Gyrus                | priming  | predicted_label | subject         | 2.1688e-08  |\n",
    "| 143 | Talairach Gyrus                | priming  | predicted_label | priming         | 8.33995e-11 |\n",
    "| 146 | Talairach Ba                   | emotion  | subject         | predicted_label | 1.0813e-14  |\n",
    "| 149 | Talairach Ba                   | emotion  | emotion         | predicted_label | 5.71776e-18 |\n",
    "| 153 | Talairach Ba                   | emotion  | predicted_label | subject         | 1.0813e-14  |\n",
    "| 154 | Talairach Ba                   | emotion  | predicted_label | emotion         | 5.71776e-18 |\n",
    "| 157 | Talairach Ba                   | priming  | subject         | priming         | 0.0110959   |\n",
    "| 158 | Talairach Ba                   | priming  | subject         | predicted_label | 6.78411e-10 |\n",
    "| 162 | Talairach Ba                   | priming  | priming         | subject         | 0.0110959   |\n",
    "| 164 | Talairach Ba                   | priming  | priming         | predicted_label | 7.54032e-12 |\n",
    "| 165 | Talairach Ba                   | priming  | predicted_label | subject         | 6.78411e-10 |\n",
    "| 167 | Talairach Ba                   | priming  | predicted_label | priming         | 7.54032e-12 |\n",
    "| 170 | Schaefer 100 x 7 x 1           | emotion  | subject         | predicted_label | 3.15156e-11 |\n",
    "| 173 | Schaefer 100 x 7 x 1           | emotion  | emotion         | predicted_label | 4.63282e-20 |\n",
    "| 177 | Schaefer 100 x 7 x 1           | emotion  | predicted_label | subject         | 3.15156e-11 |\n",
    "| 178 | Schaefer 100 x 7 x 1           | emotion  | predicted_label | emotion         | 4.63282e-20 |\n",
    "| 181 | Schaefer 100 x 7 x 1           | priming  | subject         | priming         | 0.028542    |\n",
    "| 182 | Schaefer 100 x 7 x 1           | priming  | subject         | predicted_label | 3.1785e-06  |\n",
    "| 186 | Schaefer 100 x 7 x 1           | priming  | priming         | subject         | 0.028542    |\n",
    "| 188 | Schaefer 100 x 7 x 1           | priming  | priming         | predicted_label | 1.97688e-09 |\n",
    "| 189 | Schaefer 100 x 7 x 1           | priming  | predicted_label | subject         | 3.1785e-06  |\n",
    "| 191 | Schaefer 100 x 7 x 1           | priming  | predicted_label | priming         | 1.97688e-09 |\n",
    "| 194 | Talairach Hemi x Lobe x Tissue | emotion  | subject         | predicted_label | 4.50854e-10 |\n",
    "| 197 | Talairach Hemi x Lobe x Tissue | emotion  | emotion         | predicted_label | 2.66277e-18 |\n",
    "| 201 | Talairach Hemi x Lobe x Tissue | emotion  | predicted_label | subject         | 4.50854e-10 |\n",
    "| 202 | Talairach Hemi x Lobe x Tissue | emotion  | predicted_label | emotion         | 2.66277e-18 |\n",
    "| 206 | Talairach Hemi x Lobe x Tissue | priming  | subject         | predicted_label | 2.07008e-13 |\n",
    "| 212 | Talairach Hemi x Lobe x Tissue | priming  | priming         | predicted_label | 1.19176e-13 |\n",
    "| 213 | Talairach Hemi x Lobe x Tissue | priming  | predicted_label | subject         | 2.07008e-13 |\n",
    "| 215 | Talairach Hemi x Lobe x Tissue | priming  | predicted_label | priming         | 1.19176e-13 |\n",
    "| 218 | PCA                            | emotion  | subject         | predicted_label | 4.07589e-06 |\n",
    "| 221 | PCA                            | emotion  | emotion         | predicted_label | 9.77144e-18 |\n",
    "| 225 | PCA                            | emotion  | predicted_label | subject         | 4.07589e-06 |\n",
    "| 226 | PCA                            | emotion  | predicted_label | emotion         | 9.77144e-18 |\n",
    "| 230 | PCA                            | priming  | subject         | predicted_label | 6.50613e-06 |\n",
    "| 236 | PCA                            | priming  | priming         | predicted_label | 3.01385e-08 |\n",
    "| 237 | PCA                            | priming  | predicted_label | subject         | 6.50613e-06 |\n",
    "| 239 | PCA                            | priming  | predicted_label | priming         | 3.01385e-08 |\n",
    "| 242 | Isomap                         | emotion  | subject         | predicted_label | 6.93036e-12 |\n",
    "| 245 | Isomap                         | emotion  | emotion         | predicted_label | 3.06135e-19 |\n",
    "| 249 | Isomap                         | emotion  | predicted_label | subject         | 6.93036e-12 |\n",
    "| 250 | Isomap                         | emotion  | predicted_label | emotion         | 3.06135e-19 |\n",
    "| 254 | Isomap                         | priming  | subject         | predicted_label | 8.35953e-10 |\n",
    "| 260 | Isomap                         | priming  | priming         | predicted_label | 6.55251e-13 |\n",
    "| 261 | Isomap                         | priming  | predicted_label | subject         | 8.35953e-10 |\n",
    "| 263 | Isomap                         | priming  | predicted_label | priming         | 6.55251e-13 |\n",
    "| 266 | Hessian                        | emotion  | subject         | predicted_label | 2.57359e-11 |\n",
    "| 269 | Hessian                        | emotion  | emotion         | predicted_label | 3.12609e-19 |\n",
    "| 272 | Hessian                        | emotion  | priming         | predicted_label | 0.0053442   |\n",
    "| 273 | Hessian                        | emotion  | predicted_label | subject         | 2.57359e-11 |\n",
    "| 274 | Hessian                        | emotion  | predicted_label | emotion         | 3.12609e-19 |\n",
    "| 275 | Hessian                        | emotion  | predicted_label | priming         | 0.0053442   |\n",
    "| 277 | Hessian                        | priming  | subject         | priming         | 0.0101041   |\n",
    "| 278 | Hessian                        | priming  | subject         | predicted_label | 1.91236e-08 |\n",
    "| 282 | Hessian                        | priming  | priming         | subject         | 0.0101041   |\n",
    "| 284 | Hessian                        | priming  | priming         | predicted_label | 2.6625e-11  |\n",
    "| 285 | Hessian                        | priming  | predicted_label | subject         | 1.91236e-08 |\n",
    "| 287 | Hessian                        | priming  | predicted_label | priming         | 2.6625e-11  |\n",
    "| 290 | MDS                            | emotion  | subject         | predicted_label | 3.94796e-13 |\n",
    "| 293 | MDS                            | emotion  | emotion         | predicted_label | 9.87621e-19 |\n",
    "| 297 | MDS                            | emotion  | predicted_label | subject         | 3.94796e-13 |\n",
    "| 298 | MDS                            | emotion  | predicted_label | emotion         | 9.87621e-19 |\n",
    "| 301 | MDS                            | priming  | subject         | priming         | 0.0449593   |\n",
    "| 302 | MDS                            | priming  | subject         | predicted_label | 1.95642e-16 |\n",
    "| 306 | MDS                            | priming  | priming         | subject         | 0.0449593   |\n",
    "| 308 | MDS                            | priming  | priming         | predicted_label | 6.04516e-16 |\n",
    "| 309 | MDS                            | priming  | predicted_label | subject         | 1.95642e-16 |\n",
    "| 311 | MDS                            | priming  | predicted_label | priming         | 6.04516e-16 |\n",
    "| 314 | t-SNE                          | emotion  | subject         | predicted_label | 3.42867e-27 |\n",
    "| 317 | t-SNE                          | emotion  | emotion         | predicted_label | 3.25836e-19 |\n",
    "| 321 | t-SNE                          | emotion  | predicted_label | subject         | 3.42867e-27 |\n",
    "| 322 | t-SNE                          | emotion  | predicted_label | emotion         | 3.25836e-19 |\n",
    "| 326 | t-SNE                          | priming  | subject         | predicted_label | 5.98094e-29 |\n",
    "| 332 | t-SNE                          | priming  | priming         | predicted_label | 4.60754e-19 |\n",
    "| 333 | t-SNE                          | priming  | predicted_label | subject         | 5.98094e-29 |\n",
    "| 335 | t-SNE                          | priming  | predicted_label | priming         | 4.60754e-19 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "641ae228-962b-48b7-8de1-4c252dac7ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get directories to find and store data\n",
    "input_dir = \"./data/log_reg_results/coefficients\"\n",
    "output_dir = \"./data/interpretation\"\n",
    "\n",
    "def merge_all_coefs(label, col_names):\n",
    "    dfs = []\n",
    "\n",
    "    for method in feat_ex_methods:\n",
    "        filename = f\"{method}_{label}.csv\"\n",
    "        file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "        df = df.rename(columns={\"Unnamed: 0\": \"feature\"})\n",
    "        df['method'] = [method] * len(df)\n",
    "        dfs.append(df)\n",
    "\n",
    "    # Vertical concat\n",
    "    merged_df = pd.concat(dfs, axis=0, ignore_index=True)\n",
    "    merged_df = merged_df.rename(columns=col_names)\n",
    "    merged_df.to_csv(os.path.join(output_dir, f\"coef_{label}.csv\"), index=False)\n",
    "\n",
    "    \n",
    "\n",
    "# run for both labels\n",
    "merge_all_coefs(\"emotion\", {'anger': 'anger_coefs', 'fear': 'fear_coefs', 'disgust': 'disgust_coefs'})\n",
    "merge_all_coefs(\"priming\", {'incongruent': 'incongruent_coefs', 'congruent': 'congruent_coefs', 'neutral': 'neutral_coefs'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "7f6b423d-a9a6-48d9-bcb3-53b5d8cb430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_top_coef_features(df, coef_columns, output_filename, top_n=5):\n",
    "    \n",
    "    top_features = []\n",
    "\n",
    "    for col in coef_columns:\n",
    "        \n",
    "        df_sorted = df[['feature', 'method', col]].copy()\n",
    "        df_sorted['abs_val'] = df_sorted[col].abs()\n",
    "        df_sorted = df_sorted.sort_values(by='abs_val', ascending=False).head(top_n)\n",
    "\n",
    "       \n",
    "        df_sorted['label'] = col\n",
    "        df_sorted = df_sorted[['feature', 'method', 'label', col]]\n",
    "        df_sorted = df_sorted.rename(columns={col: 'coef'})\n",
    "\n",
    "        top_features.append(df_sorted)\n",
    "\n",
    "\n",
    "    top_df = pd.concat(top_features, ignore_index=True)\n",
    "    top_df.to_csv(output_filename, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01150ef3-8d0d-4177-b2ae-8fc867612930",
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_emotion = pd.read_csv('./data/interpretation/coef_emotion.csv')\n",
    "coef_priming = pd.read_csv('./data/interpretation/coef_priming.csv')\n",
    "\n",
    "save_top_coef_features(coef_emotion, ['anger_coefs', 'fear_coefs', 'disgust_coefs'], './data/interpretation/top_coef_emotion.csv')\n",
    "save_top_coef_features(coef_priming, ['neutral_coefs', 'congruent_coefs', 'incongruent_coefs'], './data/interpretation/top_coef_priming.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b9f90fec-3a30-43d2-873d-70d4a523c503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | feature                                                    | method                     | label         |      coef |\n",
      "|---:|:-----------------------------------------------------------|:---------------------------|:--------------|----------:|\n",
      "|  0 | Brodmann area 11                                           | Talairach Ba               | anger_coefs   |  0.997122 |\n",
      "|  1 | Left Lingual Gyrus                                         | Harvard_Oxford cortl 0 x 1 | anger_coefs   |  0.75641  |\n",
      "|  2 | Middle Frontal Gyrus                                       | Talairach Gyrus            | anger_coefs   | -0.725181 |\n",
      "|  3 | b'7Networks_LH_Vis_8'                                      | Schaefer 100 x 7 x 1       | anger_coefs   | -0.723426 |\n",
      "|  4 | Left Occipital Fusiform Gyrus                              | Harvard_Oxford cortl 0 x 1 | anger_coefs   | -0.71395  |\n",
      "|  5 | Right Central Opercular Cortex                             | Harvard_Oxford cortl 0 x 1 | fear_coefs    | -0.862423 |\n",
      "|  6 | Brodmann area 11                                           | Talairach Ba               | fear_coefs    | -0.783936 |\n",
      "|  7 | Pulvinar                                                   | Talairach Ba               | fear_coefs    | -0.700187 |\n",
      "|  8 | Calcarine_L                                                | AAL SPM12                  | fear_coefs    |  0.688515 |\n",
      "|  9 | Brodmann area 43                                           | Talairach Ba               | fear_coefs    | -0.664949 |\n",
      "| 10 | GM Visual cortex V2 BA18                                   | Juelich 0 x 1              | disgust_coefs |  0.713902 |\n",
      "| 11 | GM Secondary somatosensory cortex / Parietal operculum OP2 | Juelich 0 x 1              | disgust_coefs | -0.696101 |\n",
      "| 12 | Right Central Opercular Cortex                             | Harvard_Oxford cortl 0 x 1 | disgust_coefs |  0.690772 |\n",
      "| 13 | Vermis_9                                                   | AAL SPM12                  | disgust_coefs | -0.613373 |\n",
      "| 14 | Caudate_R                                                  | AAL SPM12                  | disgust_coefs | -0.605213 |\n",
      "\n",
      "|    | feature                                      | method                         | label             |      coef |\n",
      "|---:|:---------------------------------------------|:-------------------------------|:------------------|----------:|\n",
      "|  0 | Middle Temporal Gyrus                        | Talairach Gyrus                | neutral_coefs     |  1.7935   |\n",
      "|  1 | Middle Temporal Gyrus, temporooccipital part | Harvard_Oxford cort 0 x 1      | neutral_coefs     |  1.3369   |\n",
      "|  2 | Brodmann area 39                             | Talairach Ba                   | neutral_coefs     |  1.20373  |\n",
      "|  3 | Temporal Lobe                                | Talairach Hemi x Lobe x Tissue | neutral_coefs     |  1.19578  |\n",
      "|  4 | GM Inferior parietal lobule PGp              | Juelich 0 x 1                  | neutral_coefs     |  1.10605  |\n",
      "|  5 | Middle Temporal Gyrus                        | Talairach Gyrus                | congruent_coefs   | -1.04918  |\n",
      "|  6 | Feat 7                                       | Hessian                        | congruent_coefs   |  0.858455 |\n",
      "|  7 | Posterior Cingulate                          | Talairach Gyrus                | congruent_coefs   | -0.818125 |\n",
      "|  8 | Feat 4                                       | Hessian                        | congruent_coefs   | -0.806589 |\n",
      "|  9 | GM Broca's area BA44                         | Juelich 0 x 1                  | congruent_coefs   | -0.79721  |\n",
      "| 10 | Temporal Lobe                                | Talairach Hemi x Lobe x Tissue | incongruent_coefs | -1.1329   |\n",
      "| 11 | Lateral Occipital Cortex, inferior division  | Harvard_Oxford cort 0 x 1      | incongruent_coefs | -1.07     |\n",
      "| 12 | GM Inferior parietal lobule Pga              | Juelich 0 x 1                  | incongruent_coefs | -0.983688 |\n",
      "| 13 | Lingual Gyrus                                | Talairach Gyrus                | incongruent_coefs |  0.967608 |\n",
      "| 14 | Limbic Lobe                                  | Talairach Hemi x Lobe x Tissue | incongruent_coefs |  0.948026 |\n"
     ]
    }
   ],
   "source": [
    "print(pd.read_csv('./data/interpretation/top_coef_emotion.csv').to_markdown())\n",
    "print()\n",
    "print(pd.read_csv('./data/interpretation/top_coef_priming.csv').to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "785c24bf-bb2c-4835-abb4-e96031a0a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    |   roc_train_emo |   roc_test_emo | method                         |   roc_train_pri |   roc_test_pri |   feature_count |   emo_overfit |   pri_overfit |\n",
      "|---:|----------------:|---------------:|:-------------------------------|----------------:|---------------:|----------------:|--------------:|--------------:|\n",
      "|  0 |        0.855926 |       0.560631 | Harvard_Oxford cort 0 x 1      |        0.992428 |       0.813374 |              49 |      0.654999 |      0.81958  |\n",
      "|  1 |        0.986241 |       0.54406  | Harvard_Oxford cortl 0 x 1     |        1        |       0.782291 |              97 |      0.55165  |      0.782291 |\n",
      "|  2 |        0.708313 |       0.520329 | Harvard_Oxford sub 0 x 1       |        0.777956 |       0.623964 |              22 |      0.734604 |      0.802056 |\n",
      "|  3 |        0.886845 |       0.573813 | Juelich 0 x 1                  |        0.997613 |       0.806996 |              63 |      0.647028 |      0.808927 |\n",
      "|  4 |        0.99893  |       0.528944 | AAL SPM12                      |        1        |       0.779451 |             117 |      0.52951  |      0.779451 |\n",
      "|  5 |        0.887435 |       0.511838 | Talairach Gyrus                |        0.996543 |       0.808189 |              56 |      0.576761 |      0.810993 |\n",
      "|  6 |        0.940521 |       0.536461 | Talairach Ba                   |        0.999767 |       0.773416 |              72 |      0.570387 |      0.773596 |\n",
      "|  7 |        0.999246 |       0.539355 | Schaefer 100 x 7 x 1           |        1        |       0.853937 |             101 |      0.539763 |      0.853937 |\n",
      "|  8 |        0.697915 |       0.506626 | Talairach Hemi x Lobe x Tissue |        0.859081 |       0.698985 |              23 |      0.725913 |      0.813643 |\n",
      "|  9 |        1        |       0.531509 | PCA                            |        1        |       0.855309 |             227 |      0.531509 |      0.855309 |\n",
      "| 10 |        0.864842 |       0.480521 | Isomap                         |        1        |       0.670309 |              52 |      0.555617 |      0.670309 |\n",
      "| 11 |        0.625144 |       0.497558 | Hessian                        |        0.860809 |       0.798477 |              22 |      0.79591  |      0.927589 |\n",
      "| 12 |        0.578765 |       0.488532 | MDS                            |        0.697298 |       0.61904  |               6 |      0.844094 |      0.88777  |\n",
      "| 13 |        0.529575 |       0.47904  | t-SNE                          |        0.532044 |       0.506447 |               4 |      0.904574 |      0.95189  |\n"
     ]
    }
   ],
   "source": [
    "roc_auc_scores = pd.read_csv('./data/log_reg_results/metrics/roc_auc.csv')\n",
    "roc_auc_scores['emo_overfit'] = roc_auc_scores['roc_test_emo'] / roc_auc_scores['roc_train_emo']\n",
    "roc_auc_scores['pri_overfit'] = roc_auc_scores['roc_test_pri'] / roc_auc_scores['roc_train_pri']\n",
    "print(roc_auc_scores.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3d54de63-93bb-4d21-ba4d-414ea848c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories\n",
    "input_dir = \"./data/log_reg_results/classification_reports\"\n",
    "output_file = \"./data/interpretation/f1_scores.csv\"\n",
    "\n",
    "def merge_f1_scores(feat_ex_methods):\n",
    "    rows = []\n",
    "\n",
    "    for method in feat_ex_methods:\n",
    "        row = {\n",
    "            \"method\": method,\n",
    "            \"congruent\": None,\n",
    "            \"incongruent\": None,\n",
    "            \"neutral\": None,\n",
    "            \"anger\": None,\n",
    "            \"disgust\": None,\n",
    "            \"fear\": None\n",
    "        }\n",
    "\n",
    "        for label in [\"priming\", \"emotion\"]:\n",
    "            filename = f\"{method}_{label}_test.csv\"\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "\n",
    "            if not os.path.exists(file_path):\n",
    "                continue\n",
    "\n",
    "            df = pd.read_csv(file_path)\n",
    "            df = df.rename(columns={\"Unnamed: 0\": \"class\"})\n",
    "            df = df.set_index(\"class\")\n",
    "\n",
    "            for target_class in row.keys():\n",
    "                if target_class in df.index:\n",
    "                    row[target_class] = df.loc[target_class, \"f1-score\"]\n",
    "\n",
    "        rows.append(row)\n",
    "\n",
    "    final_df = pd.DataFrame(rows)\n",
    "    final_df.to_csv(output_file, index=False)\n",
    "\n",
    "\n",
    "merge_f1_scores(feat_ex_methods)\n",
    "f1_scores = pd.read_csv(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e7e5b397-aaeb-419d-ac70-6792eebcd359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_top_f1_methods(df, cols, output_filename, top_n=5):\n",
    "    \n",
    "    top_features = []\n",
    "\n",
    "    for col in cols:\n",
    "        \n",
    "        # Sort by absolute value of coefficient, descending\n",
    "        df_sorted = df[['method', col]].copy()\n",
    "        df_sorted = df_sorted.sort_values(by=col, ascending=False).head(top_n)\n",
    "\n",
    "        # Add label info\n",
    "        df_sorted['label'] = col\n",
    "        df_sorted = df_sorted[['method', 'label', col]]\n",
    "        df_sorted = df_sorted.rename(columns={col: 'f1'})\n",
    "\n",
    "        top_features.append(df_sorted)\n",
    "\n",
    "    # Combine and save\n",
    "    top_df = pd.concat(top_features, ignore_index=True)\n",
    "    top_df.to_csv(output_filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6cc9ad07-4126-427f-a8bd-686c532f69a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | method                         | label       |       f1 |\n",
      "|---:|:-------------------------------|:------------|---------:|\n",
      "|  0 | PCA                            | congruent   | 0.715789 |\n",
      "|  1 | Talairach Gyrus                | congruent   | 0.649123 |\n",
      "|  2 | Schaefer 100 x 7 x 1           | congruent   | 0.627451 |\n",
      "|  3 | Harvard_Oxford cort 0 x 1      | congruent   | 0.616667 |\n",
      "|  4 | Juelich 0 x 1                  | congruent   | 0.597938 |\n",
      "|  5 | Schaefer 100 x 7 x 1           | incongruent | 0.688889 |\n",
      "|  6 | PCA                            | incongruent | 0.678899 |\n",
      "|  7 | Juelich 0 x 1                  | incongruent | 0.659091 |\n",
      "|  8 | Harvard_Oxford cortl 0 x 1     | incongruent | 0.629213 |\n",
      "|  9 | Talairach Hemi x Lobe x Tissue | incongruent | 0.607143 |\n",
      "| 10 | Schaefer 100 x 7 x 1           | neutral     | 0.769231 |\n",
      "| 11 | Talairach Gyrus                | neutral     | 0.736842 |\n",
      "| 12 | Juelich 0 x 1                  | neutral     | 0.705882 |\n",
      "| 13 | Harvard_Oxford cort 0 x 1      | neutral     | 0.693333 |\n",
      "| 14 | Hessian                        | neutral     | 0.666667 |\n",
      "| 15 | Talairach Ba                   | anger       | 0.48     |\n",
      "| 16 | Juelich 0 x 1                  | anger       | 0.463158 |\n",
      "| 17 | AAL SPM12                      | anger       | 0.453782 |\n",
      "| 18 | MDS                            | anger       | 0.412698 |\n",
      "| 19 | PCA                            | anger       | 0.396226 |\n",
      "| 20 | Harvard_Oxford sub 0 x 1       | disgust     | 0.361702 |\n",
      "| 21 | Schaefer 100 x 7 x 1           | disgust     | 0.337079 |\n",
      "| 22 | Talairach Hemi x Lobe x Tissue | disgust     | 0.318841 |\n",
      "| 23 | Juelich 0 x 1                  | disgust     | 0.315789 |\n",
      "| 24 | t-SNE                          | disgust     | 0.307692 |\n",
      "| 25 | Juelich 0 x 1                  | fear        | 0.505051 |\n",
      "| 26 | Talairach Hemi x Lobe x Tissue | fear        | 0.432    |\n",
      "| 27 | PCA                            | fear        | 0.426966 |\n",
      "| 28 | Harvard_Oxford cortl 0 x 1     | fear        | 0.422222 |\n",
      "| 29 | Harvard_Oxford sub 0 x 1       | fear        | 0.404762 |\n"
     ]
    }
   ],
   "source": [
    "f1_file = './data/interpretation/top_f1.csv'\n",
    "save_top_f1_methods(f1_scores, ['congruent', 'incongruent', 'neutral', 'anger', 'disgust', 'fear'], \n",
    "                       f1_file, top_n=5)\n",
    "print(pd.read_csv(f1_file).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "46804583-d018-4835-a851-55a75bc6e0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# chi square association for misclassified samples\n",
    "cat_vars = ['subject', 'emotion', 'priming', 'predicted_label']\n",
    "cat_var_pairs = [(a, b) for a, b in product(cat_vars, repeat=2) if a != b]\n",
    "\n",
    "results = []\n",
    "\n",
    "for method in feat_ex_methods:\n",
    "    for target in ['emotion', 'priming']:\n",
    "        # Load data\n",
    "        df_path = f'./data/log_reg_results/errors/{method}_{target}.csv'\n",
    "        df = pd.read_csv(df_path)\n",
    "\n",
    "        for feat1, feat2 in cat_var_pairs:\n",
    "            try:\n",
    "                contingency_table = pd.crosstab(df[feat1], df[feat2])\n",
    "                _, p_value, _, _ = stats.chi2_contingency(contingency_table)\n",
    "                results.append({\n",
    "                    'method': method,\n",
    "                    'target': target,\n",
    "                    'feat_1': feat1,\n",
    "                    'feat_2': feat2,\n",
    "                    'p_value': p_value\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error in chi-squared test for {method} - {target} - {feat1} vs {feat2}: {e}\")\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "\n",
    "output_path = './data/interpretation/chi_squared_cat_var_associations.csv'\n",
    "results_df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e44dfbd7-87f4-43ea-90ec-88f0b2fc7675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     | method                         | target   | feat_1          | feat_2          |     p_value |\n",
      "|----:|:-------------------------------|:---------|:----------------|:----------------|------------:|\n",
      "|   2 | Harvard_Oxford cort 0 x 1      | emotion  | subject         | predicted_label | 3.8911e-09  |\n",
      "|   5 | Harvard_Oxford cort 0 x 1      | emotion  | emotion         | predicted_label | 2.07755e-17 |\n",
      "|   9 | Harvard_Oxford cort 0 x 1      | emotion  | predicted_label | subject         | 3.8911e-09  |\n",
      "|  10 | Harvard_Oxford cort 0 x 1      | emotion  | predicted_label | emotion         | 2.07755e-17 |\n",
      "|  13 | Harvard_Oxford cort 0 x 1      | priming  | subject         | priming         | 0.0498261   |\n",
      "|  14 | Harvard_Oxford cort 0 x 1      | priming  | subject         | predicted_label | 4.37921e-12 |\n",
      "|  18 | Harvard_Oxford cort 0 x 1      | priming  | priming         | subject         | 0.0498261   |\n",
      "|  20 | Harvard_Oxford cort 0 x 1      | priming  | priming         | predicted_label | 1.43065e-10 |\n",
      "|  21 | Harvard_Oxford cort 0 x 1      | priming  | predicted_label | subject         | 4.37921e-12 |\n",
      "|  23 | Harvard_Oxford cort 0 x 1      | priming  | predicted_label | priming         | 1.43065e-10 |\n",
      "|  26 | Harvard_Oxford cortl 0 x 1     | emotion  | subject         | predicted_label | 8.45044e-12 |\n",
      "|  29 | Harvard_Oxford cortl 0 x 1     | emotion  | emotion         | predicted_label | 2.9766e-18  |\n",
      "|  33 | Harvard_Oxford cortl 0 x 1     | emotion  | predicted_label | subject         | 8.45044e-12 |\n",
      "|  34 | Harvard_Oxford cortl 0 x 1     | emotion  | predicted_label | emotion         | 2.9766e-18  |\n",
      "|  37 | Harvard_Oxford cortl 0 x 1     | priming  | subject         | priming         | 0.00683838  |\n",
      "|  38 | Harvard_Oxford cortl 0 x 1     | priming  | subject         | predicted_label | 1.21349e-08 |\n",
      "|  42 | Harvard_Oxford cortl 0 x 1     | priming  | priming         | subject         | 0.00683838  |\n",
      "|  44 | Harvard_Oxford cortl 0 x 1     | priming  | priming         | predicted_label | 1.83898e-12 |\n",
      "|  45 | Harvard_Oxford cortl 0 x 1     | priming  | predicted_label | subject         | 1.21349e-08 |\n",
      "|  47 | Harvard_Oxford cortl 0 x 1     | priming  | predicted_label | priming         | 1.83898e-12 |\n",
      "|  50 | Harvard_Oxford sub 0 x 1       | emotion  | subject         | predicted_label | 1.09737e-06 |\n",
      "|  53 | Harvard_Oxford sub 0 x 1       | emotion  | emotion         | predicted_label | 5.6732e-18  |\n",
      "|  57 | Harvard_Oxford sub 0 x 1       | emotion  | predicted_label | subject         | 1.09737e-06 |\n",
      "|  58 | Harvard_Oxford sub 0 x 1       | emotion  | predicted_label | emotion         | 5.6732e-18  |\n",
      "|  62 | Harvard_Oxford sub 0 x 1       | priming  | subject         | predicted_label | 1.22515e-06 |\n",
      "|  68 | Harvard_Oxford sub 0 x 1       | priming  | priming         | predicted_label | 4.61949e-15 |\n",
      "|  69 | Harvard_Oxford sub 0 x 1       | priming  | predicted_label | subject         | 1.22515e-06 |\n",
      "|  71 | Harvard_Oxford sub 0 x 1       | priming  | predicted_label | priming         | 4.61949e-15 |\n",
      "|  74 | Juelich 0 x 1                  | emotion  | subject         | predicted_label | 2.35824e-11 |\n",
      "|  77 | Juelich 0 x 1                  | emotion  | emotion         | predicted_label | 7.82954e-17 |\n",
      "|  81 | Juelich 0 x 1                  | emotion  | predicted_label | subject         | 2.35824e-11 |\n",
      "|  82 | Juelich 0 x 1                  | emotion  | predicted_label | emotion         | 7.82954e-17 |\n",
      "|  86 | Juelich 0 x 1                  | priming  | subject         | predicted_label | 4.95935e-06 |\n",
      "|  92 | Juelich 0 x 1                  | priming  | priming         | predicted_label | 7.45783e-12 |\n",
      "|  93 | Juelich 0 x 1                  | priming  | predicted_label | subject         | 4.95935e-06 |\n",
      "|  95 | Juelich 0 x 1                  | priming  | predicted_label | priming         | 7.45783e-12 |\n",
      "|  98 | AAL SPM12                      | emotion  | subject         | predicted_label | 6.64931e-16 |\n",
      "| 101 | AAL SPM12                      | emotion  | emotion         | predicted_label | 1.02118e-17 |\n",
      "| 105 | AAL SPM12                      | emotion  | predicted_label | subject         | 6.64931e-16 |\n",
      "| 106 | AAL SPM12                      | emotion  | predicted_label | emotion         | 1.02118e-17 |\n",
      "| 109 | AAL SPM12                      | priming  | subject         | priming         | 0.012332    |\n",
      "| 110 | AAL SPM12                      | priming  | subject         | predicted_label | 1.09439e-10 |\n",
      "| 114 | AAL SPM12                      | priming  | priming         | subject         | 0.012332    |\n",
      "| 116 | AAL SPM12                      | priming  | priming         | predicted_label | 9.39201e-13 |\n",
      "| 117 | AAL SPM12                      | priming  | predicted_label | subject         | 1.09439e-10 |\n",
      "| 119 | AAL SPM12                      | priming  | predicted_label | priming         | 9.39201e-13 |\n",
      "| 122 | Talairach Gyrus                | emotion  | subject         | predicted_label | 5.82423e-08 |\n",
      "| 125 | Talairach Gyrus                | emotion  | emotion         | predicted_label | 5.13539e-19 |\n",
      "| 129 | Talairach Gyrus                | emotion  | predicted_label | subject         | 5.82423e-08 |\n",
      "| 130 | Talairach Gyrus                | emotion  | predicted_label | emotion         | 5.13539e-19 |\n",
      "| 133 | Talairach Gyrus                | priming  | subject         | priming         | 0.00201984  |\n",
      "| 134 | Talairach Gyrus                | priming  | subject         | predicted_label | 2.1688e-08  |\n",
      "| 138 | Talairach Gyrus                | priming  | priming         | subject         | 0.00201984  |\n",
      "| 140 | Talairach Gyrus                | priming  | priming         | predicted_label | 8.33995e-11 |\n",
      "| 141 | Talairach Gyrus                | priming  | predicted_label | subject         | 2.1688e-08  |\n",
      "| 143 | Talairach Gyrus                | priming  | predicted_label | priming         | 8.33995e-11 |\n",
      "| 146 | Talairach Ba                   | emotion  | subject         | predicted_label | 1.0813e-14  |\n",
      "| 149 | Talairach Ba                   | emotion  | emotion         | predicted_label | 5.71776e-18 |\n",
      "| 153 | Talairach Ba                   | emotion  | predicted_label | subject         | 1.0813e-14  |\n",
      "| 154 | Talairach Ba                   | emotion  | predicted_label | emotion         | 5.71776e-18 |\n",
      "| 157 | Talairach Ba                   | priming  | subject         | priming         | 0.0110959   |\n",
      "| 158 | Talairach Ba                   | priming  | subject         | predicted_label | 6.78411e-10 |\n",
      "| 162 | Talairach Ba                   | priming  | priming         | subject         | 0.0110959   |\n",
      "| 164 | Talairach Ba                   | priming  | priming         | predicted_label | 7.54032e-12 |\n",
      "| 165 | Talairach Ba                   | priming  | predicted_label | subject         | 6.78411e-10 |\n",
      "| 167 | Talairach Ba                   | priming  | predicted_label | priming         | 7.54032e-12 |\n",
      "| 170 | Schaefer 100 x 7 x 1           | emotion  | subject         | predicted_label | 3.15156e-11 |\n",
      "| 173 | Schaefer 100 x 7 x 1           | emotion  | emotion         | predicted_label | 4.63282e-20 |\n",
      "| 177 | Schaefer 100 x 7 x 1           | emotion  | predicted_label | subject         | 3.15156e-11 |\n",
      "| 178 | Schaefer 100 x 7 x 1           | emotion  | predicted_label | emotion         | 4.63282e-20 |\n",
      "| 181 | Schaefer 100 x 7 x 1           | priming  | subject         | priming         | 0.028542    |\n",
      "| 182 | Schaefer 100 x 7 x 1           | priming  | subject         | predicted_label | 3.1785e-06  |\n",
      "| 186 | Schaefer 100 x 7 x 1           | priming  | priming         | subject         | 0.028542    |\n",
      "| 188 | Schaefer 100 x 7 x 1           | priming  | priming         | predicted_label | 1.97688e-09 |\n",
      "| 189 | Schaefer 100 x 7 x 1           | priming  | predicted_label | subject         | 3.1785e-06  |\n",
      "| 191 | Schaefer 100 x 7 x 1           | priming  | predicted_label | priming         | 1.97688e-09 |\n",
      "| 194 | Talairach Hemi x Lobe x Tissue | emotion  | subject         | predicted_label | 4.50854e-10 |\n",
      "| 197 | Talairach Hemi x Lobe x Tissue | emotion  | emotion         | predicted_label | 2.66277e-18 |\n",
      "| 201 | Talairach Hemi x Lobe x Tissue | emotion  | predicted_label | subject         | 4.50854e-10 |\n",
      "| 202 | Talairach Hemi x Lobe x Tissue | emotion  | predicted_label | emotion         | 2.66277e-18 |\n",
      "| 206 | Talairach Hemi x Lobe x Tissue | priming  | subject         | predicted_label | 2.07008e-13 |\n",
      "| 212 | Talairach Hemi x Lobe x Tissue | priming  | priming         | predicted_label | 1.19176e-13 |\n",
      "| 213 | Talairach Hemi x Lobe x Tissue | priming  | predicted_label | subject         | 2.07008e-13 |\n",
      "| 215 | Talairach Hemi x Lobe x Tissue | priming  | predicted_label | priming         | 1.19176e-13 |\n",
      "| 218 | PCA                            | emotion  | subject         | predicted_label | 4.07589e-06 |\n",
      "| 221 | PCA                            | emotion  | emotion         | predicted_label | 9.77144e-18 |\n",
      "| 225 | PCA                            | emotion  | predicted_label | subject         | 4.07589e-06 |\n",
      "| 226 | PCA                            | emotion  | predicted_label | emotion         | 9.77144e-18 |\n",
      "| 230 | PCA                            | priming  | subject         | predicted_label | 6.50613e-06 |\n",
      "| 236 | PCA                            | priming  | priming         | predicted_label | 3.01385e-08 |\n",
      "| 237 | PCA                            | priming  | predicted_label | subject         | 6.50613e-06 |\n",
      "| 239 | PCA                            | priming  | predicted_label | priming         | 3.01385e-08 |\n",
      "| 242 | Isomap                         | emotion  | subject         | predicted_label | 6.93036e-12 |\n",
      "| 245 | Isomap                         | emotion  | emotion         | predicted_label | 3.06135e-19 |\n",
      "| 249 | Isomap                         | emotion  | predicted_label | subject         | 6.93036e-12 |\n",
      "| 250 | Isomap                         | emotion  | predicted_label | emotion         | 3.06135e-19 |\n",
      "| 254 | Isomap                         | priming  | subject         | predicted_label | 8.35953e-10 |\n",
      "| 260 | Isomap                         | priming  | priming         | predicted_label | 6.55251e-13 |\n",
      "| 261 | Isomap                         | priming  | predicted_label | subject         | 8.35953e-10 |\n",
      "| 263 | Isomap                         | priming  | predicted_label | priming         | 6.55251e-13 |\n",
      "| 266 | Hessian                        | emotion  | subject         | predicted_label | 2.57359e-11 |\n",
      "| 269 | Hessian                        | emotion  | emotion         | predicted_label | 3.12609e-19 |\n",
      "| 272 | Hessian                        | emotion  | priming         | predicted_label | 0.0053442   |\n",
      "| 273 | Hessian                        | emotion  | predicted_label | subject         | 2.57359e-11 |\n",
      "| 274 | Hessian                        | emotion  | predicted_label | emotion         | 3.12609e-19 |\n",
      "| 275 | Hessian                        | emotion  | predicted_label | priming         | 0.0053442   |\n",
      "| 277 | Hessian                        | priming  | subject         | priming         | 0.0101041   |\n",
      "| 278 | Hessian                        | priming  | subject         | predicted_label | 1.91236e-08 |\n",
      "| 282 | Hessian                        | priming  | priming         | subject         | 0.0101041   |\n",
      "| 284 | Hessian                        | priming  | priming         | predicted_label | 2.6625e-11  |\n",
      "| 285 | Hessian                        | priming  | predicted_label | subject         | 1.91236e-08 |\n",
      "| 287 | Hessian                        | priming  | predicted_label | priming         | 2.6625e-11  |\n",
      "| 290 | MDS                            | emotion  | subject         | predicted_label | 3.94796e-13 |\n",
      "| 293 | MDS                            | emotion  | emotion         | predicted_label | 9.87621e-19 |\n",
      "| 297 | MDS                            | emotion  | predicted_label | subject         | 3.94796e-13 |\n",
      "| 298 | MDS                            | emotion  | predicted_label | emotion         | 9.87621e-19 |\n",
      "| 301 | MDS                            | priming  | subject         | priming         | 0.0449593   |\n",
      "| 302 | MDS                            | priming  | subject         | predicted_label | 1.95642e-16 |\n",
      "| 306 | MDS                            | priming  | priming         | subject         | 0.0449593   |\n",
      "| 308 | MDS                            | priming  | priming         | predicted_label | 6.04516e-16 |\n",
      "| 309 | MDS                            | priming  | predicted_label | subject         | 1.95642e-16 |\n",
      "| 311 | MDS                            | priming  | predicted_label | priming         | 6.04516e-16 |\n",
      "| 314 | t-SNE                          | emotion  | subject         | predicted_label | 3.42867e-27 |\n",
      "| 317 | t-SNE                          | emotion  | emotion         | predicted_label | 3.25836e-19 |\n",
      "| 321 | t-SNE                          | emotion  | predicted_label | subject         | 3.42867e-27 |\n",
      "| 322 | t-SNE                          | emotion  | predicted_label | emotion         | 3.25836e-19 |\n",
      "| 326 | t-SNE                          | priming  | subject         | predicted_label | 5.98094e-29 |\n",
      "| 332 | t-SNE                          | priming  | priming         | predicted_label | 4.60754e-19 |\n",
      "| 333 | t-SNE                          | priming  | predicted_label | subject         | 5.98094e-29 |\n",
      "| 335 | t-SNE                          | priming  | predicted_label | priming         | 4.60754e-19 |\n"
     ]
    }
   ],
   "source": [
    "print(results_df[results_df['p_value'] <= .05].to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2edc9f-fae6-470f-a736-cd147b30f523",
   "metadata": {},
   "source": [
    "## **Relationship Between Results**\n",
    "\n",
    "Visualize pair plot for feature-based analysis: model coefficients, autocorrelation coefficients, vif\n",
    "Visualize pair plot for method-based analysis: feature count, f1, roc_auc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "972e2b9d-fd72-496c-8836-60ed51c4a834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# join all feature-focused dataframes on \"feature\" column\n",
    "\n",
    "# join all method-focused dataframes on \"method\" column\n",
    "\n",
    "# identify the relationship between methods collected at each stage of the investigation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
